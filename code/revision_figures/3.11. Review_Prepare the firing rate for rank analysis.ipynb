{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "from neo.core import SpikeTrain\n",
    "from quantities import ms, s, Hz\n",
    "from elephant.statistics import mean_firing_rate\n",
    "from elephant.statistics import time_histogram, instantaneous_rate\n",
    "from elephant.kernels import GaussianKernel\n",
    "from elephant.statistics import mean_firing_rate\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"G:/My Drive/WORKING_MEMORY/EXPERIMENTS/ELECTROPHYSIOLOGY/ANALYSIS/src/functions/\")\n",
    "import ephys_functions as ephys\n",
    "import model_functions as mod\n",
    "import behavioral_functions as beh\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings. filterwarnings('ignore', category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the synch data from the paper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"G:/My Drive/WORKING_MEMORY/PAPER/ANALYSIS_Figures/instantaneous firing rate_alltrial_5ms.csv\", index_col=0)\n",
    "df_final = pd.read_csv(\"G:/My Drive/WORKING_MEMORY/PAPER/WM_manuscript_FIGURES/Fig. 7. Synch/synch_data_trials_2beforeSti.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = \"E22_2022-01-13_16-34-24.csv\"\n",
    "for animal in df_final.animal.unique():\n",
    "    # file_name = 'synch_data_trials_2beforeSti'\n",
    "    # df_final = pd.read_csv(file_name+'.csv', index_col=0)\n",
    "    threshold = 0.5\n",
    "\n",
    "    df_session = df_final.loc[df_final.animal==animal]\n",
    "\n",
    "    fig, ax = plt.subplots(2,1 , figsize=(10,6))\n",
    "    panel = ax[0]\n",
    "    panel1 = ax[1]\n",
    "\n",
    "\n",
    "    sns.lineplot(x=\"trial\", y=\"synch_window\",data=df_session, color='black',ci=68,ax=panel)      \n",
    "    sns.lineplot(x=\"trial\", y=\"synch\",data=df_session, color='grey',ci=68,ax=panel1)      \n",
    "    for plot in [panel, panel1]:\n",
    "        plot.set_ylabel('Synch')\n",
    "        plot.set_ylim(0.9,max(df_session.synch_window)+0.3)\n",
    "        plot.fill_between(df_session['trial'],0.9 , 2.5, where=df_session['WM_roll'] <= threshold,\n",
    "                    facecolor='indigo', alpha=0.3)\n",
    "        plot.fill_between(df_session['trial'], 0.9, 2.5,  where=df_session['WM_roll'] >= threshold,\n",
    "                        facecolor='darkgreen', alpha=0.3)\n",
    "    panel.set_xlabel('Trials')\n",
    "    panel.set_title('Mouse E22 13-01')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-do to obtain activity per bin for all neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\Ephys\\summary_complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E04_2021-03-30_11-20-16.csv\n",
      "E04_2021-03-30_11-20-16complete_graph.pdf\n",
      "E04_2021-04-03_16-12-15.csv\n",
      "E04_2021-04-03_16-12-15complete_graph.pdf\n",
      "E11_2021-05-12_12-56-16.csv\n",
      "E11_2021-05-12_12-56-16complete_graph.pdf\n",
      "E11_2021-05-13_12-34-49.csv\n",
      "E11_2021-05-13_12-34-49complete_graph.pdf\n",
      "E11_2021-05-14_14-27-21.csv\n",
      "E11_2021-05-14_14-27-21complete_graph.pdf\n",
      "E11_2021-05-24_14-33-29.csv\n",
      "E11_2021-05-24_14-33-29complete_graph.pdf\n",
      "E11_2021-05-26_12-20-58.csv\n",
      "E11_2021-05-26_12-20-58complete_graph.pdf\n",
      "E11_2021-05-27_12-15-58.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiffany.ona\\AppData\\Local\\Temp\\ipykernel_27448\\3232338482.py:9: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path + \"/\"+ filename, sep=',',index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E11_2021-05-27_12-15-58complete_graph.pdf\n",
      "E13_2021-05-25_16-26-57.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiffany.ona\\AppData\\Local\\Temp\\ipykernel_27448\\3232338482.py:9: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path + \"/\"+ filename, sep=',',index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E13_2021-05-25_16-26-57complete_graph.pdf\n",
      "E13_2021-05-26_15-01-42.csv\n",
      "E13_2021-05-26_15-01-42complete_graph.pdf\n",
      "E13_2021-06-06_11-29-34.csv\n",
      "E13_2021-06-06_11-29-34complete_graph.pdf\n",
      "E13_2021-06-08_11-22-23.csv\n",
      "E13_2021-06-08_11-22-23complete_graph.pdf\n",
      "E13_2021-06-09_12-14-21.csv\n",
      "E13_2021-06-09_12-14-21complete_graph.pdf\n",
      "E14_2021-03-29_13-01-12.csv\n",
      "E14_2021-03-29_13-01-12complete_graph.pdf\n",
      "E14_2021-03-31_13-07-18.csv\n",
      "E14_2021-03-31_13-07-18complete_graph.pdf\n",
      "E14_2021-04-02_12-53-42.csv\n"
     ]
    }
   ],
   "source": [
    "# List of variables we want to recover\n",
    "bin_size = 0.02\n",
    "concat_df = pd.DataFrame()\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    print(filename)   \n",
    "\n",
    "    if filename[-3:] != 'pdf':\n",
    "        df = pd.read_csv(path + \"/\"+ filename, sep=',',index_col=0)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Add time before stimulus from the previous trial\n",
    "    df = ephys.add_time_before_stimulus(df, 4)\n",
    "    \n",
    "    for align, start, stop, delay_epoch in zip(['END'],[-2],\n",
    "                                               [0],[False]):\n",
    "\n",
    "        # Sort per trial\n",
    "        df = df.sort_values('trial')\n",
    "        # Get unique neurons in the whole session\n",
    "        unique_neurons = df.cluster_id.unique()\n",
    "        \n",
    "        #Create new aligment to the end of the session\n",
    "        df['a_'+align] = df.fixed_times-df[align]\n",
    "\n",
    "        # Define bin edges (e.g., 20 ms bins up to max time)\n",
    "        bins = np.arange(-2, 0 + bin_size, bin_size)\n",
    "        bin_labels = bins[:-1]  # Labels for bins (start times)\n",
    "\n",
    "        # Assign each spike to a time bin\n",
    "        df['a_END_bin'] = pd.cut(df['a_END'], bins=bins, labels=bin_labels, include_lowest=True)\n",
    "        \n",
    "        # Skip sessions with less than 30 neurons\n",
    "        total_neurons_session = len(df.cluster_id.unique())\n",
    "        if total_neurons_session < 30:\n",
    "            continue\n",
    "            \n",
    "        for T in df.trial.unique(): \n",
    "            # Select the trial that we want to look at this time\n",
    "            dft = df.loc[df.trial ==T]\n",
    "            \n",
    "            # Create a DataFrame with all possible combinations of cluster_id and a_END_bin\n",
    "            all_combinations = pd.MultiIndex.from_product([unique_neurons, bin_labels], names=['cluster_id', 'a_END_bin']).to_frame(index=False)\n",
    "        \n",
    "            # Merge with the actual data to fill missing combinations with NaNs\n",
    "            binned_spikes = pd.merge(all_combinations, dft.groupby(['cluster_id', 'a_END_bin']).size().reset_index(name='spike_count'), on=['cluster_id', 'a_END_bin'], how='left')\n",
    "\n",
    "            # Fill NaNs in spike_count with 0\n",
    "            binned_spikes['spike_count'].fillna(0, inplace=True)\n",
    "\n",
    "            # Convert 'time_bin' back to numeric\n",
    "            binned_spikes['a_END_bin'] = binned_spikes['a_END_bin'].astype(float)\n",
    "            binned_spikes['trial'] = T\n",
    "            binned_spikes['session'] = filename\n",
    "            binned_spikes['WM_roll'] = dft.WM_roll.unique()[0]\n",
    "            concat_df = pd.concat([concat_df, binned_spikes], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>WM</th>\n",
       "      <th>mean_trial</th>\n",
       "      <th>std_trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E04_2021-03-30_11-20-16.csv</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E04_2021-03-30_11-20-16.csv</td>\n",
       "      <td>1</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       session  WM  mean_trial  std_trial\n",
       "0  E04_2021-03-30_11-20-16.csv   0         7.0        0.0\n",
       "1  E04_2021-03-30_11-20-16.csv   1       184.0        0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = concat_df.drop_duplicates(subset=['session', 'cluster_id', 'trial', 'WM'])\n",
    "grp1 = df.groupby(['session', 'WM', 'cluster_id']).trial.nunique().reset_index()\n",
    "grp2 = grp1.groupby(['session', 'WM']).agg(mean_trial = ('trial', 'mean'), std_trial = ('trial', 'std')).reset_index()\n",
    "grp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df['WM'] = np.where(concat_df['WM_roll'] > 0.5, 1, 0)\n",
    "concat_df.drop(columns=['WM_roll'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv(r'C:\\Users\\tiffany.ona\\Documents\\working_memory\\data\\3_11_Review_Prepare the firing rate for rank analysis\\20ms_rank_df_fixed_V2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.read_csv(r'C:\\Users\\tiffany.ona\\Documents\\working_memory\\data\\3_11_Review_Prepare the firing rate for rank analysis\\20ms_rank_df_fixed.csv', index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

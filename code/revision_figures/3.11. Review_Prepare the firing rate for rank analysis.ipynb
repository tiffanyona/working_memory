{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "from neo.core import SpikeTrain\n",
    "from quantities import ms, s, Hz\n",
    "from elephant.statistics import mean_firing_rate\n",
    "from elephant.statistics import time_histogram, instantaneous_rate\n",
    "from elephant.kernels import GaussianKernel\n",
    "from elephant.statistics import mean_firing_rate\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"G:/My Drive/WORKING_MEMORY/EXPERIMENTS/ELECTROPHYSIOLOGY/ANALYSIS/src/functions/\")\n",
    "import ephys_functions as ephys\n",
    "import model_functions as mod\n",
    "import behavioral_functions as beh\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings. filterwarnings('ignore', category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the synch data from the paper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"G:/My Drive/WORKING_MEMORY/PAPER/ANALYSIS_Figures/instantaneous firing rate_alltrial_5ms.csv\", index_col=0)\n",
    "df_final = pd.read_csv(\"G:/My Drive/WORKING_MEMORY/PAPER/WM_manuscript_FIGURES/Fig. 7. Synch/synch_data_trials_2beforeSti.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = \"E22_2022-01-13_16-34-24.csv\"\n",
    "for animal in df_final.animal.unique():\n",
    "    # file_name = 'synch_data_trials_2beforeSti'\n",
    "    # df_final = pd.read_csv(file_name+'.csv', index_col=0)\n",
    "    threshold = 0.5\n",
    "\n",
    "    df_session = df_final.loc[df_final.animal==animal]\n",
    "\n",
    "    fig, ax = plt.subplots(2,1 , figsize=(10,6))\n",
    "    panel = ax[0]\n",
    "    panel1 = ax[1]\n",
    "\n",
    "\n",
    "    sns.lineplot(x=\"trial\", y=\"synch_window\",data=df_session, color='black',ci=68,ax=panel)      \n",
    "    sns.lineplot(x=\"trial\", y=\"synch\",data=df_session, color='grey',ci=68,ax=panel1)      \n",
    "    for plot in [panel, panel1]:\n",
    "        plot.set_ylabel('Synch')\n",
    "        plot.set_ylim(0.9,max(df_session.synch_window)+0.3)\n",
    "        plot.fill_between(df_session['trial'],0.9 , 2.5, where=df_session['WM_roll'] <= threshold,\n",
    "                    facecolor='indigo', alpha=0.3)\n",
    "        plot.fill_between(df_session['trial'], 0.9, 2.5,  where=df_session['WM_roll'] >= threshold,\n",
    "                        facecolor='darkgreen', alpha=0.3)\n",
    "    panel.set_xlabel('Trials')\n",
    "    panel.set_title('Mouse E22 13-01')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-do to obtain activity per bin for all neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\Ephys\\summary_complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables we want to recover\n",
    "mean_firing= []\n",
    "cv=[]\n",
    "synch = []\n",
    "repeat_list=[]\n",
    "hit_list=[]\n",
    "wm_list=[]\n",
    "animal_list = []\n",
    "T_max = []\n",
    "trial = []\n",
    "synch_mean_window=[]\n",
    "aligment_window=[]\n",
    "surrogates=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename[-3:] != 'pdf':\n",
    "        df = pd.read_csv(path + \"/\"+ filename, sep=',',index_col=0)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    print(filename)   \n",
    "    \n",
    "    df = ephys.add_time_before_stimulus(df, 4)\n",
    "\n",
    "    #Filter for the last 2 seconds of the ITI\n",
    "    df = df.loc[df.a_END>start]\n",
    "    \n",
    "    for align, start, stop, delay_epoch in zip(['END'],[-2],\n",
    "                                               [0],[False]):\n",
    "\n",
    "        #Create new aligment to the end of the session\n",
    "        df['a_'+align] = df.fixed_times-df[align]\n",
    "\n",
    "        # Sort per trial\n",
    "        df = df.sort_values('trial')\n",
    "\n",
    "        #Filter for the last 2 seconds of the ITI\n",
    "        df = df.loc[(df['a_'+align]>start)&(df['a_'+align]<stop)]\n",
    "\n",
    "        # total_neurons_session = len(df.loc[(df.trial_start<df.trial)&(df.trial_end>df.trial)].cluster_id.unique())\n",
    "        total_neurons_session = len(df.cluster_id.unique())\n",
    "        if total_neurons_session < 30:\n",
    "            continue\n",
    "            \n",
    "        print('There are ' + str(total_neurons_session) + ' neurons')\n",
    "\n",
    "        for T in df.trial.unique(): \n",
    "            # Select the trial that we want to look at this time\n",
    "            dft = df.loc[df.trial ==T]\n",
    "                \n",
    "            dft = dft.loc[(dft['a_'+align]>start)&(dft['a_'+align]<stop)]\n",
    "\n",
    "            # Recover amount of neurons that were being registered at that trial interval\n",
    "    #         n_neurons = len(df.loc[(df.trial_start<T)&(df.trial_end>T)].cluster_id.unique())\n",
    "            n_neurons = len(df.cluster_id.unique())\n",
    "\n",
    "            # Values for module\n",
    "            # print(\"The HB value for this trial is \", dft.accuracy.unique()[0])\n",
    "            # print(\"The WM value for this trial is \", dft.repeat_bias.unique()[0])\n",
    "\n",
    "            if len(dft) <2:\n",
    "                continue\n",
    "\n",
    "            hit_list.append(dft.hit.unique()[0])\n",
    "            repeat_list.append(dft.repeat_choice.unique()[0])\n",
    "            wm_list.append(dft.WM_roll.unique()[0])\n",
    "\n",
    "            if delay_epoch:\n",
    "                # if dft.delay.unique()[0] == 0.1 or dft.delay.unique()[0] == 0.2:\n",
    "                if dft.delay.unique()[0] != 1 and dft.delay.unique()[0] == 3 and dft.delay.unique()[0] == 3:\n",
    "                    mean_firing.append(np.nan)\n",
    "                    synch.append(np.nan)\n",
    "                    trial.append(T)\n",
    "                    animal_list.append(filename)\n",
    "                    aligment_window.append(align+'_'+str(start)+'_'+str(stop))\n",
    "                    T_max.append(max(df.trial.unique()))\n",
    "                    continue\n",
    "                    \n",
    "            times_spikes = dft['a_'+align].values\n",
    "            times_spikes = times_spikes*1000*ms #transform to ms\n",
    "\n",
    "            ############################################################ Set the strat and end time of the train\n",
    "            stop_time =  stop*1000*ms ## End of the trial in ms\n",
    "            start_time = start*1000*ms ## Start of the trial in ms     \n",
    "\n",
    "            ############################################################ Spiketrain\n",
    "            spiketrain = SpikeTrain(times_spikes, units=ms, t_stop=stop_time, t_start=start_time) \n",
    "\n",
    "            ############################################################ \n",
    "            histogram_rate = time_histogram([spiketrain], 20*ms, output='counts')\n",
    "            times_ = histogram_rate.times.rescale(s)\n",
    "            firing_real = histogram_rate.rescale(histogram_rate.dimensionality).magnitude.flatten()\n",
    "\n",
    "            mean_firing.append(float(mean_firing_rate(spiketrain)/n_neurons*1000))\n",
    "            print(\"The mean firing rate of spiketrain is\", mean_firing_rate(spiketrain)/n_neurons)\n",
    "\n",
    "            print(\"The std of the firing rate of spiketrain is\", np.std(firing))\n",
    "            real_std=np.std(firing_real) # Store the real std value\n",
    "\n",
    "            # t1_start = process_time() \n",
    "            list_std = []\n",
    "            for i in range(surrogates):\n",
    "                # Create a random shuffle for the same amount of spikes in that interval\n",
    "                random_float_list = np.random.uniform(start, stop, len(times_spikes))\n",
    "                # t1_stop = process_time() \n",
    "                # print(str(T) + ' ' + str(t1_stop-t1_start))\n",
    "                \n",
    "                surrogate_spikes = np.array(random_float_list)*1000*ms #transform to ms\n",
    "                spiketrain = SpikeTrain(surrogate_spikes, units=ms, t_stop=stop_time, t_start=start_time) \n",
    "\n",
    "                histogram_rate = time_histogram([spiketrain], 20*ms, output='rate')\n",
    "                times_ = histogram_rate.times.rescale(s)\n",
    "                firing = histogram_rate.rescale(histogram_rate.dimensionality).magnitude.flatten()\n",
    "\n",
    "                list_std.append(np.std(firing))\n",
    "\n",
    "            synch.append(real_std/np.mean(list_std))\n",
    "            \n",
    "            trial.append(T)\n",
    "            animal_list.append(filename)\n",
    "            aligment_window.append(align+'_'+str(start)+'_'+str(stop))\n",
    "            T_max.append(max(df.trial.unique()))\n",
    "\n",
    "            # Organized by cluster_id and corrected for FR ____________________________\n",
    "#             cluster_id=[]\n",
    "#             FR_mean=[]\n",
    "\n",
    "#             for N in df.cluster_id.unique():\n",
    "#                 spikes = dft.loc[dft.cluster_id==N]['a_'+align].values\n",
    "#                 FR_mean.append(len(spikes)/abs(stop-start))\n",
    "#                 cluster_id.append(N)\n",
    "\n",
    "#             df_spikes = pd.DataFrame(list(zip(cluster_id,FR_mean)), columns =['cluster_id','FR'])\n",
    "#             df_spikes = df_spikes.sort_values('FR')\n",
    "#             df_spikes['new_order'] = np.arange(len(df_spikes))\n",
    "\n",
    "#             dft = pd.merge(df_spikes, dft, on=['cluster_id'])\n",
    "\n",
    "#             print('Synch:', real_std/np.mean(list_std), '; WM:', str(dft.WM_roll.unique()[0]))\n",
    "\n",
    "#             fig, (ax,ax1)= plt.subplots(2, 1,figsize=(10, 6), sharex=True)\n",
    "\n",
    "#             j=0\n",
    "#             for N in dft.new_order.unique():\n",
    "#                 spikes = dft.loc[dft.new_order==N]['a_'+align].values\n",
    "#                 j+=1\n",
    "#                 ax.plot(spikes,np.repeat(j, len(spikes)), '|', markersize=5, color='black', zorder=1)\n",
    "\n",
    "#             # sns.scatterplot(x='a_'+align,y='cluster_id',data=dft, ax=ax, size=1, legend=False, marker='|') # Plot neuron per neuron, not corrected by cluster_id\n",
    "#             # ax.eventplot([spiketrain], linelengths=0.75, color='black') # Plot all neurons together in a spiketrain\n",
    "\n",
    "#             ax.set_title('Trial: ' + str(T))\n",
    "#             ax1.plot(times_,firing_real/n_neurons*1000)\n",
    "#             ax1.set_xlabel('Time (s) from end of the trial', fontsize=16)\n",
    "#             sns.despine()\n",
    "#             plt.show()\n",
    "\n",
    "        # Create new dataframe with all the recovered lists. \n",
    "        # df_final = pd.DataFrame(list(zip(synch, np.arange(len(synch)))),\n",
    "        #        columns =['synch','trial'])\n",
    "        # synch_window= compute_window_centered(df_final,5,'synch')\n",
    "        # synch_mean_window.extend(synch_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with all the recovered lists. \n",
    "df_final = pd.DataFrame(list(zip(mean_firing, synch, hit_list, wm_list, repeat_list, T_max,trial,animal_list, aligment_window)), \n",
    "       columns =['FR', 'synch','hit','WM_roll','repeat','total trials','trial','animal', 'aligment'])\n",
    "\n",
    "df_final.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['accuracy'] = compute_window_centered(df_final,10,'hit')\n",
    "df_final['repeat_bias'] = compute_window_centered(df_final,10,'repeat')\n",
    "df_final['synch_window']= compute_window_centered(df_final,5,'synch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trials(row):\n",
    "    val = 0\n",
    "    val = row['trial']/row['total trials']\n",
    "    return val\n",
    "\n",
    "df_final['T_norm'] = df_final.apply(trials, axis=1) \n",
    "df_final['z_synch_window'] = stats.zscore(df_final['synch_window'].values, nan_policy='omit')\n",
    "df_final['z_synch'] = stats.zscore(df_final['synch'].values, nan_policy='omit')\n",
    "df_final['z_FR'] = stats.zscore(df_final['FR'].values, nan_policy='omit')\n",
    "df_final['state'] = np.where(df_final['WM_roll'] >0.6, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/Tiffany/Google Drive/WORKING_MEMORY/PAPER/Figures/'\n",
    "os.chdir(save_path)\n",
    "file_name = 'synch_data'\n",
    "df_final.to_csv(file_name+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measure activity of a specific bin for the rank analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_extraction_trial(df, cluster_list=[], variable = 'vector_answer', align = 'Delay_OFF', start = 0, stop = 1, delay_only=False):\n",
    "    y = []\n",
    "    d = {}\n",
    "    \n",
    "    if delay_only == False:\n",
    "        # print('Skipping delays')\n",
    "        if align == 'Delay_OFF' and start < 0:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "        if align == 'Delay_OFF' and start < -1:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2) & (df.delay != 1)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 0.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 1.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2) & (df.delay != 1)]\n",
    "    \n",
    "    # print('Recovered from: ', str(len(df.trial.unique())), ' trials')\n",
    "    # Create new aligment to the end of the session\n",
    "    df['a_'+align] = df.fixed_times-df[align]\n",
    "\n",
    "    # cluster_list = df_all.cluster_id.unique()\n",
    "    df = df.sort_values('trial')\n",
    "    \n",
    "    y = df.groupby('trial')[variable].mean()\n",
    "\n",
    "    # Filter for the spikes that occur in the interval we are analyzing\n",
    "    df = df.loc[(df['a_'+align]>start)&(df['a_'+align]<stop)]\n",
    "\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final = df.groupby(['trial','cluster_id']).count()\n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final = df_final.pivot_table(index=['trial'], columns='cluster_id', values='fixed_times', fill_value=0).rename_axis(None, axis=1)\n",
    "    df_final = df_final.reindex(cluster_list, axis=1,fill_value=0)\n",
    "\n",
    "    result = pd.merge(df_final, y, how=\"right\", on=[\"trial\"]).fillna(0)\n",
    "    result = result.rename(columns={variable: \"y\"})\n",
    "    result['y'] = np.where(result['y'] == 0, -1, result['y']) \n",
    "    \n",
    "    return result, result['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename[-3:] != 'pdf':\n",
    "        df = pd.read_csv(path + \"/\"+ filename, sep=',',index_col=0)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    print(filename)   \n",
    "    \n",
    "    df = ephys.add_time_before_stimulus(df, 4)\n",
    "    df = df.sort_values('trial')\n",
    "\n",
    "    df['delay'] = np.around(df.delay,2)\n",
    "    df['state'] = np.where(df['WM_roll'] >0.6, 1, 0)\n",
    "    \n",
    "    decode = 'vector_answer'\n",
    "    align='Stimulus_ON'\n",
    "    start = -2\n",
    "    stop = 0\n",
    "    cluster_list = df.cluster_id.unique()\n",
    "    for T in df.trial.unique():\n",
    "        for start_, stop_ in np.arange(start, stop, 0.020):\n",
    "            print(T)\n",
    "            df_final, y = interval_extraction_trial(df, variable = decode, align = align, start = start, stop = stop, cluster_list=cluster_list)\n",
    "            df_final.reset_index(inplace=True)\n",
    "            df_final = df_final.drop(columns ='trial')\n",
    "            df_final['state'] = df['state']\n",
    "            df_final['trial'] = T\n",
    "            df_final['session'] = filename\n",
    "            df_final['times'] =  str(start_) + '_' + str(stop_)\n",
    "            \n",
    "            # session, trial, times, state, cluster_id, count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magig  tools\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"G:/My Drive/WORKING_MEMORY/EXPERIMENTS/ELECTROPHYSIOLOGY/ANALYSIS/src/functions/\")\n",
    "import ephys_functions as ephys\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings. filterwarnings('ignore', category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r'E:\\Ephys\\summary_complete'\n",
    "save_data = r'G:\\My Drive\\WORKING_MEMORY\\PAPER\\2ND_SUBMISSION_NAT_NEURO\\data_for_resubmission'\n",
    "save_figures = r'G:\\My Drive\\WORKING_MEMORY\\PAPER\\2ND_SUBMISSION_NAT_NEURO\\figures_for_resubmission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_extraction(df, cluster_list=[], decode='vector_answer', align='Delay_OFF', start:float=0.0, stop=1.0, delay_only=False):\n",
    "    y = []\n",
    "    d = {}\n",
    "\n",
    "    if delay_only == False:\n",
    "        # print('Skipping delays')\n",
    "        if align == 'Delay_OFF' and start < 0:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "        if align == 'Delay_OFF' and start < -1.1:\n",
    "            df = df.loc[(df.delay != 0.1) & (\n",
    "                df.delay != 0.2) & (df.delay != 1)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 0.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 1.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (\n",
    "                df.delay != 0.2) & (df.delay != 1)]\n",
    "\n",
    "    # print('Recovered from: ', str(len(df.trial.unique())), ' trials')\n",
    "    # Create new aligment to the end of the session\n",
    "    df['a_'+align] = df.fixed_times-df[align]\n",
    "\n",
    "    # cluster_list = df_all.cluster_id.unique()\n",
    "    df = df.sort_values('trial')\n",
    "    \n",
    "    # Filter for the spikes that occur in the interval we are analyzing\n",
    "    df = df.loc[(df['a_'+align] > start) & (df['a_'+align] < stop)]\n",
    "\n",
    "    y = df.groupby('trial')[decode].first()\n",
    "    \n",
    "    df_final = pd.DataFrame()\n",
    "    df_final = df.groupby(['trial', 'cluster_id']).count()\n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final = df_final.pivot_table(\n",
    "        index=['trial'], columns='cluster_id', values='fixed_times', fill_value=0).rename_axis(None, axis=1)\n",
    "    df_final = df_final.reindex(cluster_list, axis=1, fill_value=0)\n",
    "\n",
    "    result = pd.merge(df_final, y, how=\"right\", on=[\"trial\"]).fillna(0)\n",
    "    result = result.rename(columns={decode: \"y\"})\n",
    "    result['y'] = np.where(result['y'] == 0, -1, result['y'])\n",
    "\n",
    "    return result, result['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________\n",
    "# Decode external drive across different conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Look for the code splitting and aligning on stimulus and delay_OFF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_final, decode='vector_answer', align='Delay_OFF', start=-0.5, stop=0, cluster_list = [], \n",
    "            ratio=0.65, test_index=[],  train_index=[], fakey=[], delay_only=False):\n",
    "    \n",
    "    # This is mainly for the session shuffles\n",
    "    if len(fakey) > 1:\n",
    "        print('Using shuffled session')\n",
    "        y = fakey[len(fakey)-len(y):]\n",
    "        df_final['y'] = y   \n",
    "        \n",
    "    train_cols = df_final.columns\n",
    "        \n",
    "    if len(test_index) >= 1:\n",
    "        train = df_final.loc[train_index,:]\n",
    "        test = df_final.loc[test_index,:]\n",
    "        x_test = test.iloc[:, test.columns != 'y']\n",
    "        y_test = test['y']\n",
    "        x_train = train.iloc[:, train.columns != 'y']\n",
    "        y_train = train['y']\n",
    "        \n",
    "    else:\n",
    "        x_train = df_final.iloc[:, df_final.columns != 'y']\n",
    "        y_train = df_final['y']\n",
    "        x_test = x_train\n",
    "        y_test = y_train\n",
    "\n",
    "        \n",
    "    #Normalize the X data\n",
    "    # sc = RobustScaler()\n",
    "    # sc_fit = sc.fit(x_train)\n",
    "    # x_train = sc.fit_transform(x_train)\n",
    "    # x_test = sc.fit_transform(x_test)\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', penalty = 'l2', class_weight='balanced').fit(x_train, y_train)\n",
    "    # model = LogisticRegression(solver='liblinear', penalty = 'l1', C=0.9).fit(x_train, y_train)\n",
    "\n",
    "    train_cols = df_final.columns\n",
    "    \n",
    "    p_pred = model.predict_proba(x_test)    \n",
    "    y_pred = model.predict(x_test)    \n",
    "    f1score= f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    y_test = np.where(y_test == -1, 0, y_test) \n",
    "    y_new = y_test.reshape(len(y_test), 1).astype(int)\n",
    "    score_ =  np.take_along_axis(p_pred,y_new,axis=1)   \n",
    "\n",
    "    print('score:', np.mean(score_), 'f1_score ', f1score)\n",
    "    \n",
    "    return model, train_cols, np.mean(score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(df,model, epoch='Stimulus_ON',initrange=-0.4,endrange=1.5,r=0.2, train_cols=None, variable='ra_accuracy',\n",
    "                      hit=1, nsurrogates = 100, decode='vector_answer', ratio=0, cluster_list = [], test_index=[], fakey=[], \n",
    "                        delay_only=False, score_options = 'standard'):\n",
    "    '''\n",
    "    Function that tests a previously trained function (func. train_decoder) on population activity of specific segments\n",
    "    \n",
    "    Attributes\n",
    "        - df: DataFrame. it contains a whole ephys session without curation. \n",
    "        - WM and RL are the variables to consider a trial in the RL or in the WM-module. Both need to be floats. \n",
    "        - epoch: str. Moment at which the data will be aligned to. \n",
    "        - initrange: float. \n",
    "        - endrange: float.\n",
    "        - r: float \n",
    "        - model. function. \n",
    "        - train_cols\n",
    "        - name. String\n",
    "        - variables. List. \n",
    "        - hits. List. \n",
    "        - colors. List\n",
    "        - nsurrogates. Int. \n",
    "        - indexes. List \n",
    "        - decode. String\n",
    "    \n",
    "    Return\n",
    "        - df_real\n",
    "        - df_iter\n",
    "        It will also make a plot. \n",
    "    '''\n",
    "    \n",
    "    df_real = pd.DataFrame()\n",
    "    df_iter = pd.DataFrame(columns = ['iteration','score', 'times','epoch' ,'variable'])\n",
    "    \n",
    "\n",
    "    times = [] # Timestamps\n",
    "    real_score = [] # real scoring of the decoded\n",
    "    index_iter = 0\n",
    "    print_value = True\n",
    "\n",
    "    for start, stop in zip(np.arange(initrange,endrange-r,r),np.arange(initrange+r,endrange,r)):\n",
    "        times.append((start+stop)/2)\n",
    "        df_final, y = interval_extraction(df,decode = decode, align = epoch, start = start, stop = stop, cluster_list=cluster_list, delay_only=delay_only)\n",
    "        \n",
    "        # Sometimes the testing and the trainind dataset have different neurons since they are looking at different trials and perhaps there were no spikes\n",
    "        # coming from all neurons. We compare which columns are missing and add them containing 0 for the model to work. \n",
    "        test_cols = df_final.columns\n",
    "        \n",
    "        common_cols = train_cols.intersection(test_cols)\n",
    "        train_not_test = train_cols.difference(test_cols)\n",
    "        for col in train_not_test:\n",
    "            df_final[col] = 0\n",
    "\n",
    "        #The other way round. When training in segmented data, sometimes the training set is smaller than the testing (for instance, when training in Hb trials and testing in WM)\n",
    "        test_not_train = test_cols.difference(train_cols)\n",
    "        for col in test_not_train:\n",
    "            df_final.drop(columns=[col],inplace=True)\n",
    "        \n",
    "        # Reorder so we can use the fit from the trianing of the Robustscaler\n",
    "        df_final = df_final.reindex(columns=train_cols)\n",
    "        \n",
    "        # This is for the session shuffles\n",
    "        if len(fakey) > 1:\n",
    "            print('Using shuffled session')\n",
    "            y = fakey[len(fakey)-len(y):]\n",
    "            df_final['y'] = y   \n",
    "            \n",
    "        #Train the model\"\n",
    "        if len(test_index) >= 1:\n",
    "            # Split data in training and testing\n",
    "            # x_train, x_test, y_train, y_test =\\\n",
    "            #     train_test_split(df_final, y, test_size=test_sample,random_state=random_state)\n",
    "            \n",
    "            df_final.reset_index(inplace=True)\n",
    "            df_final = df_final.drop(columns ='trial')            \n",
    "            test = df_final.loc[test_index,:]\n",
    "            # print('Fold',str(fold_no),'Class Ratio:',sum(test['y'])/len(test['y']))\n",
    "            x_test = test.iloc[:, test.columns != 'y']\n",
    "            y_test = test['y']             \n",
    "\n",
    "        else:\n",
    "            x_train = df_final.iloc[:, df_final.columns != 'y']\n",
    "            y_train = df_final['y']\n",
    "            x_test = x_train\n",
    "            y_test = y_train\n",
    "\n",
    "        #Normalize the X data\n",
    "        # sc = RobustScaler()\n",
    "        # x_test = sc.fit_transform(x_test)\n",
    "        # x_test = sc_fit.transform(x_test)\n",
    "\n",
    "        p_pred = model.predict_proba(x_test)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        if score_options == 'standard':\n",
    "            score_ = model.score(x_test, y_test)\n",
    "        \n",
    "        elif score_options == 'drive_on':\n",
    "            score_ =  p_pred[:, 1]\n",
    "            \n",
    "        elif score_options == 'drive_off':\n",
    "            score_ =  p_pred[:, 0]\n",
    "        else:\n",
    "            y_test = np.where(y_test == -1, 0, y_test)\n",
    "            y_new = y_test.reshape(len(y_test), 1).astype(int)\n",
    "            # y_new = y_test.values.reshape(len(y_test), 1).astype(int)\n",
    "            score_ =  np.take_along_axis(p_pred,y_new,axis=1)\n",
    "        \n",
    "        real_score.append(score_[0])\n",
    "\n",
    "        # precision = np.mean(precision_score(y_test, y_pred))\n",
    "        # recall = np.mean(recall_score(y_test, y_pred))\n",
    "        for i in np.arange(nsurrogates):\n",
    "            y_perr = shuffle(y_test)\n",
    "            score_ = model.score(x_test, y_perr)   \n",
    "            score_  = np.mean(score_)\n",
    "            # if score_options == 'standard':\n",
    "            #     score_ = model.score(x_test, y_perr)   \n",
    "            #     score_  = np.mean(score_)\n",
    "            # else:\n",
    "            #     # y_new = y_perr.values.reshape(len(y_perr), 1).astype(int)\n",
    "            #     y_new = y_perr.reshape(len(y_perr), 1).astype(int)\n",
    "            #     result =  np.take_along_axis(p_pred,y_new,axis=1)\n",
    "            #     score_  = np.mean(result)\n",
    "                        \n",
    "            new_row = {'iteration': i, 'score': score_, 'times': (start+stop)/2, 'epoch' : epoch, 'variable' : str(variable)+'_'+str(hit)}\n",
    "            \n",
    "            # Use the `loc` indexer to insert the row\n",
    "            df_iter.loc[index_iter] = new_row\n",
    "            index_iter +=1 \n",
    "            \n",
    "    times.append('trial_type')\n",
    "    real_score.append(variable+'_'+str(hit))\n",
    "    a_series = pd.DataFrame([real_score], columns = times)\n",
    "    df_real = pd.concat([df_real,a_series], ignore_index=True)\n",
    "    \n",
    "    return df_real, df_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trial(df,sc_fit, epoch='Stimulus_ON',initrange=-0.4,endrange=1.5,r=0.2, model = None, train_cols=None, variable='ra_accuracy',\n",
    "                      hit=1, nsurrogates = 100, decode='vector_answer', ratio=0, cluster_list = [], test_index=[], fakey=[], delay_only=False):\n",
    "    '''\n",
    "    Function that tests a previously trained function (func. train_decoder) on population activity of specific segments\n",
    "    \n",
    "    Attributes\n",
    "        - df: DataFrame. it contains a whole ephys session without curation. \n",
    "        - WM and RL are the variables to consider a trial in the RL or in the WM-module. Both need to be floats. \n",
    "        - epoch: str. Moment at which the data will be aligned to. \n",
    "        - initrange: float. \n",
    "        - endrange: float.\n",
    "        - r: float \n",
    "        - model. function. \n",
    "        - train_cols\n",
    "        - name. String\n",
    "        - variables. List. \n",
    "        - hits. List. \n",
    "        - colors. List\n",
    "        - nsurrogates. Int. \n",
    "        - indexes. List \n",
    "        - decode. String\n",
    "    \n",
    "    Return\n",
    "        - df_real\n",
    "        - df_iter\n",
    "        It will also make a plot. \n",
    "    '''\n",
    "    \n",
    "    df_real = pd.DataFrame()\n",
    "    df_iter = pd.DataFrame(columns=['iteration', 'score', 'times', 'epoch', 'variable'])\n",
    "        \n",
    "    times = [] # Timestamps\n",
    "    real_score = [] # real scoring of the decoded\n",
    "    mean_sur=[] # mean of the surrogate data\n",
    "\n",
    "    for start, stop in zip(np.arange(initrange,endrange-r,r/2),np.arange(initrange+r,endrange,r/2)):\n",
    "        times.append((start+stop)/2)\n",
    "        df_final, y = interval_extraction_trial(df,variable = decode, align = epoch, start = start, stop = stop, cluster_list=cluster_list, delay_only=delay_only)\n",
    "\n",
    "        # Sometimes the testing and the trainind dataset have different neurons since they are looking at different trials and perhaps there were no spikes\n",
    "        # coming from all neurons. We compare which columns are missing and add them containing 0 for the model to work. \n",
    "        test_cols = df_final.columns\n",
    "        common_cols = train_cols.intersection(test_cols)\n",
    "        train_not_test = train_cols.difference(test_cols)\n",
    "        for col in train_not_test:\n",
    "            df_final[col] = 0\n",
    "\n",
    "        #The other way round. When training in segmented data, sometimes the training set is smaller than the testing (for instance, when training in Hb trials and testing in WM)\n",
    "        test_not_train = test_cols.difference(train_cols)\n",
    "        for col in test_not_train:\n",
    "            df_final.drop(columns=[col],inplace=True)\n",
    "\n",
    "        #Train the model\"\n",
    "        if len(test_index) >= 1:\n",
    "            print('Train splitting trials')\n",
    "            # Split data in training and testing\n",
    "            # x_train, x_test, y_train, y_test =\\\n",
    "            #     train_test_split(df_final, y, test_size=test_sample,random_state=random_state)\n",
    "            \n",
    "            df_final.reset_index(inplace=True)\n",
    "            df_final = df_final.drop(columns ='trial')\n",
    "            test = df_final.loc[test_index,:]\n",
    "            # print('Fold',str(fold_no),'Class Ratio:',sum(test['y'])/len(test['y']))\n",
    "            x_test = test.iloc[:, test.columns != 'y']\n",
    "            y_test = test['y']             \n",
    "\n",
    "        else:\n",
    "            x_train = df_final.iloc[:, df_final.columns != 'y']\n",
    "            y_train = df_final['y']\n",
    "            x_test = x_train\n",
    "            y_test = y_train\n",
    "        \n",
    "        #Normalize the X data\n",
    "        # sc = RobustScaler()\n",
    "        # x_test = sc.fit_transform(x_test)\n",
    "        # x_test = sc_fit.transform(x_test)\n",
    "        \n",
    "        p_pred = model.predict_proba(x_test)\n",
    "        y_pred = model.predict(x_test)\n",
    "        score_ = model.score(x_test, y_test)\n",
    "        real_score.append(score_)\n",
    "\n",
    "        # y_test = np.where(y_test == -1, 0, y_test) \n",
    "        # y_new = y_test.reshape(len(y_test), 1).astype(int)\n",
    "        # corrected_score =  np.take_along_axis(p_pred,y_new,axis=1)   \n",
    "        # real_score.append(np.mean(corrected_score))\n",
    "\n",
    "        # print('score:', score_, 'corrected score: ', np.mean(corrected_score), end='\\n\\n')\n",
    "\n",
    "        i=0\n",
    "        rows = []\n",
    "        while i <= nsurrogates:\n",
    "            i+=1\n",
    "            y_perr = shuffle(y_test)\n",
    "            score_ = model.score(x_test, y_perr)\n",
    "\n",
    "            # y_new = y_perr.reshape(len(y_perr), 1).astype(int)\n",
    "            # result =  np.take_along_axis(p_pred,y_new,axis=1)     \n",
    "            # score_  = np.mean(result)\n",
    "\n",
    "            new_row = pd.DataFrame({'iteration': [i], 'score': [score_], 'times': [(start+stop)/2], 'epoch' : [epoch], \n",
    "                                      'variable' : [variable+'_'+str(hit)]})\n",
    "            df_iter = pd.concat([df_iter,new_row], ignore_index=True)\n",
    "        \n",
    "    times.append('trial_type')\n",
    "    real_score.append(variable+'_'+str(hit))\n",
    "    a_series = pd.DataFrame([real_score], columns = times)\n",
    "\n",
    "    df_real = pd.concat([df_real,a_series], ignore_index=True)\n",
    "    \n",
    "    return df_real, df_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interval_extraction_trial(df, cluster_list=[], variable = 'vector_answer', align = 'Delay_OFF', start = 0, stop = 1, delay_only=False):\n",
    "    y = []\n",
    "    d = {}\n",
    "    \n",
    "    if delay_only == False:\n",
    "        # print('Skipping delays')\n",
    "        if align == 'Delay_OFF' and start < 0:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "        if align == 'Delay_OFF' and start < -1:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2) & (df.delay != 1)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 0.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 1.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2) & (df.delay != 1)]\n",
    "    \n",
    "    # print('Recovered from: ', str(len(df.trial.unique())), ' trials')\n",
    "    # Create new aligment to the end of the session\n",
    "    df['a_'+align] = df.fixed_times-df[align]\n",
    "\n",
    "    # cluster_list = df_all.cluster_id.unique()\n",
    "    df = df.sort_values('trial')\n",
    "    \n",
    "    y = df.groupby('trial')[variable].mean()\n",
    "\n",
    "    # Filter for the spikes that occur in the interval we are analyzing\n",
    "    df = df.loc[(df['a_'+align]>start)&(df['a_'+align]<stop)]\n",
    "\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final = df.groupby(['trial','cluster_id']).count()\n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final = df_final.pivot_table(index=['trial'], columns='cluster_id', values='fixed_times', fill_value=0).rename_axis(None, axis=1)\n",
    "    df_final = df_final.reindex(cluster_list, axis=1,fill_value=0)\n",
    "\n",
    "    result = pd.merge(df_final, y, how=\"right\", on=[\"trial\"]).fillna(0)\n",
    "    result = result.rename(columns={variable: \"y\"})\n",
    "    result['y'] = np.where(result['y'] == 0, -1, result['y']) \n",
    "    \n",
    "    return result, result['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables used for decoder training\n",
    "nsplits = 2 # number of splits of the Kfold\n",
    "decode = 'drive' # decoding variable\n",
    "align = 'Stimulus_ON' # aligning epoch\n",
    "r = 0.25 # binning window\n",
    "start = -0.25 # Window to select the training window/obtain number of trials for each condition\n",
    "stop = 0.0 # Window to select the training window/obtain number of trials for each condition\n",
    "variable_train = 'WM_roll'\n",
    "hit_train = 1\n",
    "ratio_train = 0.6\n",
    "\n",
    "# Variables for testing\n",
    "colors = ['indigo', 'darkorange']\n",
    "variables_test= ['WM_roll','RL_roll']\n",
    "hits_test = [1,1]\n",
    "ratios_test = [0.6, 0.4]\n",
    "variables_combined=[variables_test[0]+'_'+str(hits_test[0]),variables_test[1]+'_'+str(hits_test[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'E:\\\\Ephys\\\\summary_complete'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_cum \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m      2\u001b[0m df_cum_shuffle \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_data\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m2\u001b[39m:]:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      5\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path_to_data \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m filename, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'E:\\\\Ephys\\\\summary_complete'"
     ]
    }
   ],
   "source": [
    "df_cum = pd.DataFrame()\n",
    "df_cum_shuffle = pd.DataFrame()\n",
    "for filename in os.listdir(path_to_data)[2:]:\n",
    "    if filename[-3:] != 'pdf':\n",
    "        df = pd.read_csv(path_to_data + \"/\" + filename, sep=',', index_col=0)\n",
    "        print(filename)\n",
    "    else:\n",
    "        continue\n",
    "    name = filename\n",
    "\n",
    "    df = ephys.add_time_before_stimulus(df, -4)\n",
    "    delay = 10\n",
    "    df['delay'] = np.around(df.delay, 2)\n",
    "    df = df.loc[df.delay == delay]\n",
    "\n",
    "    df['drive'] = np.where((df['a_'+align]>0)&(df['a_'+align] < delay + .5), 1, 0)\n",
    "    \n",
    "    # Recover all the neurons in these session. This is because sometimes in some type of trials there are no activity for some neurons\n",
    "    # even though in the training set there was. We need to fill such neurons with 0 always.\n",
    "    cluster_list = df.cluster_id.unique()\n",
    "    if hit_train == 'all' and variable_train == 'all':\n",
    "        df_train = df\n",
    "    elif hit_train == 'all':\n",
    "        df_train = df.loc[(df[variable_train] > ratio_train)]\n",
    "    elif variable_train == 'all':\n",
    "        df_train = df.loc[(df['hit'] == hit_train)]\n",
    "    else:\n",
    "        df_train = df.loc[(df[variable_train] > ratio_train)\n",
    "                          & (df.hit == hit_train)]\n",
    "\n",
    "    cum_df_final = pd.DataFrame()\n",
    "    cum_y = pd.DataFrame()\n",
    "            \n",
    "    for start, stop in zip(np.arange(-4, delay+ 0.5, r), np.arange(-4 + r, delay + 0.5 + r, r)):\n",
    "            df_final, y = interval_extraction(df_train, decode=decode, align=align, start=start, stop=stop, cluster_list=cluster_list)\n",
    "            df_final.reset_index(inplace=True)\n",
    "            df_final['times'] = str(start)+'_'+str(stop)\n",
    "            cum_df_final = pd.concat([cum_df_final, df_final], axis=0)\n",
    "            \n",
    "    # y = cum_df_final['y']\n",
    "    cum_df_final = cum_df_final.drop(columns=['trial', 'times'])\n",
    "\n",
    "    print('Trials for training: ', len(df_final))\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=nsplits, shuffle=True)\n",
    "    model, train_cols, score = train(cum_df_final, decode=decode, align=align, start=start,stop=stop, cluster_list = cluster_list)\n",
    "    fold_no=1\n",
    "    \n",
    "    for train_index, test_index in skf.split(df_final, y):\n",
    "            fig, ax1 = plt.subplots(1,1, figsize=(8, 4), sharey=True)\n",
    "\n",
    "            for color, variable, hit, ratio, left in zip(colors,variables_test, hits_test,ratios_test,[ax1,ax1,ax1,ax1]):\n",
    "                df_res = pd.DataFrame()\n",
    "                df_sti = pd.DataFrame()\n",
    "                df_iter = pd.DataFrame()\n",
    "                try:\n",
    "                    df_delay = df.loc[np.around(df.delay,1)==delay]\n",
    "                    delay=np.around(df_delay.delay.iloc[0],1)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Create a dataframe for testing data\n",
    "                if variable == 'all':\n",
    "                    df_test = df_delay.loc[(df_delay.hit==hit)]\n",
    "                elif hit == 'all':\n",
    "                    df_test = df_delay.loc[(df_delay[variable]>=ratio)]\n",
    "                else:\n",
    "                    df_test = df_delay.loc[(df_delay[variable]>=ratio)&(df_delay.hit==hit)]\n",
    "\n",
    "                if df_test.empty or df_test.trial.nunique() < 5:\n",
    "                    continue\n",
    "                \n",
    "                df_real,df_temp = test(df_test, decode= decode,epoch='Stimulus_ON',initrange=-4,endrange=delay+0.5, r=r, model = model, delay_only=delay, variable=variable, hit=hit, nsurrogates = 2, train_cols = train_cols, cluster_list = cluster_list, score_options='drive_off')\n",
    "                df_sti = pd.concat([df_real,df_sti], axis=0)\n",
    "                df_iter = pd.concat([df_iter,df_temp], axis=0)\n",
    "                \n",
    "                variable = str(variable)+'_'+str(hit)\n",
    "\n",
    "                # Aligmnent for Stimulus cue\n",
    "                real = df_sti.loc[(df_sti['trial_type'] ==variable)].to_numpy()\n",
    "                times = np.around(np.array(df_sti.columns)[:-1].astype(float),2)\n",
    "\n",
    "                df_new= df_iter.loc[(df_iter.epoch=='Stimulus_ON')].groupby('times')['score']\n",
    "                y_mean= df_new.mean().values\n",
    "                lower =  df_new.quantile(q=0.975, interpolation='linear') - y_mean\n",
    "                upper =  df_new.quantile(q=0.025, interpolation='linear') - y_mean\n",
    "                x=times\n",
    "                \n",
    "                ephys.plot_results_decoder(fig, real[0][:len(y_mean)], times, df_new,  ax1, color = color, epoch = 'Delay_OFF', \n",
    "                            y_range = [0.1, 1], x_range = None, substract=False)\n",
    "                \n",
    "                df_cum, df_cum_shuffle = ephys.add_to_summary(real[0][:len(y_mean)], y_mean, times, filename, variable, epoch = 'Stimulus_ON', fold_no=fold_no, df_iter=df_iter, df_cum=df_cum, df_cum_shuffle=df_cum_shuffle, substract=False, delay=delay)\n",
    "                \n",
    "                sns.despine()\n",
    "                fold_no +=1\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(8, 4), sharey=True)\n",
    "\n",
    "ephys.plot_results_session_summary(ax, df_cum, colors, variables_combined, \n",
    "                                 y_range = [-0.1, 1], x_range = [-2, 5], epoch = 'Stimulus_ON', baseline=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

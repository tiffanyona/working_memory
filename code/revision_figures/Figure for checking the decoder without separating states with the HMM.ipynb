{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e12800f4-4499-431c-bda5-af2ca0abc4d8",
   "metadata": {},
   "source": [
    "### **Figure for checking the decoder without separating states with the HMM**\n",
    "This to verify if we could observe the reversals if we didn't take into account the states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2910eab-53ce-4839-b866-e78dec22747b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "# warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings. filterwarnings('ignore', category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88666c9-4beb-4f41-8431-9fdd5fd016f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(df, epoch='Stimulus_ON',initrange=-0.4,endrange=1.5,r=0.2, model = None, train_cols=None, variable='ra_accuracy',\n",
    "         hit=1, nsurrogates = 100, decode='vector_answer', ratio=0, cluster_list = [], test_index=[], \n",
    "         fakey=[], delay_only=False, T=1):\n",
    "    '''\n",
    "    Function that tests a previously trained function (func. train_decoder) on population activity of specific segments\n",
    "    \n",
    "    Attributes\n",
    "        - df: DataFrame. it contains a whole ephys session without curation. \n",
    "        - WM and RL are the variables to consider a trial in the RL or in the WM-module. Both need to be floats. \n",
    "        - epoch: str. Moment at which the data will be aligned to. \n",
    "        - initrange: float. \n",
    "        - endrange: float.\n",
    "        - r: float \n",
    "        - model. function. \n",
    "        - train_cols\n",
    "        - name. String\n",
    "        - variables. List. \n",
    "        - hits. List. \n",
    "        - colors. List\n",
    "        - nsurrogates. Int. \n",
    "        - indexes. List \n",
    "        - decode. String\n",
    "    \n",
    "    Return\n",
    "        - df_real\n",
    "        - df_iter\n",
    "        It will also make a plot. \n",
    "    '''\n",
    "    \n",
    "    df_real = pd.DataFrame()\n",
    "    df_iter = pd.DataFrame()\n",
    "        \n",
    "    times = [] # Timestamps\n",
    "    real_score = [] # real scoring of the decoded\n",
    "    odds_score = [] # real scoring of the decoded\n",
    "    mean_sur=[] # mean of the surrogate data\n",
    "\n",
    "    for start, stop in zip(np.arange(initrange,endrange-r,r),np.arange(initrange+r,endrange,r)):\n",
    "        times.append((start+stop)/2)\n",
    "        df_final, y = interval_extraction_trial(df,variable = decode, align = epoch, start = start, stop = stop, cluster_list=cluster_list, delay_only=delay_only)\n",
    "        \n",
    "        # Sometimes the testing and the trainind dataset have different neurons since they are looking at different trials and perhaps there were no spikes\n",
    "        # coming from all neurons. We compare which columns are missing and add them containing 0 for the model to work. \n",
    "        test_cols = df_final.columns\n",
    "        common_cols = train_cols.intersection(test_cols)\n",
    "        train_not_test = train_cols.difference(test_cols)\n",
    "        for col in train_not_test:\n",
    "            df_final[col] = 0\n",
    "\n",
    "        #The other way round. When training in segmented data, sometimes the training set is smaller than the testing (for instance, when training in Hb trials and testing in WM)\n",
    "        test_not_train = test_cols.difference(train_cols)\n",
    "        for col in test_not_train:\n",
    "            df_final.drop(columns=[col],inplace=True)\n",
    "        \n",
    "        df_final = df_final.reindex(columns=train_cols)\n",
    "\n",
    "        #Train the model\"\n",
    "        if len(test_index) >= 1:\n",
    "            # print('Train splitting trials')\n",
    "            # Split data in training and testing\n",
    "            # x_train, x_test, y_train, y_test =\\\n",
    "            #     train_test_split(df_final, y, test_size=test_sample,random_state=random_state)\n",
    "            \n",
    "            df_final.reset_index(inplace=True)\n",
    "            df_final = df_final.drop(columns ='trial')\n",
    "            test = df_final.loc[test_index,:]\n",
    "            # print('Fold',str(fold_no),'Class Ratio:',sum(test['y'])/len(test['y']))\n",
    "            x_test = test.iloc[:, test.columns != 'y']\n",
    "            y_test = test['y']             \n",
    "\n",
    "        else:\n",
    "            x_train = df_final.iloc[:, df_final.columns != 'y']\n",
    "            y_train = df_final['y']\n",
    "            x_test = x_train\n",
    "            y_test = y_train\n",
    "        \n",
    "        #Normalize the X data\n",
    "        # sc = RobustScaler()\n",
    "        # x_test = sc.fit_transform(x_test)\n",
    "        # x_test = sc_fit.transform(x_test)\n",
    "        \n",
    "        p_pred = model.predict_proba(x_test)\n",
    "        y_pred = model.predict(x_test)\n",
    "        # score_ = model.score(x_test, y_test)\n",
    "        # real_score.append(score_)\n",
    "\n",
    "        # real_index_trial = df_final.reset_index()[df_final.index == T].index[0]\n",
    "        \n",
    "        y_test = np.where(y_test == -1, 0, y_test) \n",
    "        # y_new = y_test.values.reshape(len(y_test), 1).astype(int)\n",
    "        y_new = y_test.reshape(len(y_test), 1).astype(int)\n",
    "        corrected_score =  np.take_along_axis(p_pred, y_new, axis=1)  \n",
    "        real_score.append(np.mean(corrected_score))\n",
    "        \n",
    "        # incorrected_score =  np.repeat(1, len(corrected_score))[0] - corrected_score\n",
    "        # incorrected_score[incorrected_score == 0] = 0.001\n",
    "        # log_odds = np.log(corrected_score/incorrected_score)\n",
    "        # odds_score.append(np.mean(log_odds))\n",
    "    \n",
    "        i=0\n",
    "        while i <= nsurrogates:\n",
    "            i+=1\n",
    "            y_perr = shuffle(y_test)\n",
    "            # score_ = model.score(x_test, y_perr)\n",
    "            \n",
    "            # y_new = y_perr.values.reshape(len(y_perr), 1).astype(int)\n",
    "            y_new = y_perr.reshape(len(y_perr), 1).astype(int)\n",
    "            result =  np.take_along_axis(p_pred,y_new,axis=1)     \n",
    "            score_  = np.mean(result)\n",
    "            \n",
    "#             corrected_score =  np.take_along_axis(p_pred,y_new,axis=1)     \n",
    "#             incorrected_score =  np.repeat(1, len(corrected_score))[0] - corrected_score\n",
    "#             incorrected_score[incorrected_score == 0] = 0.001\n",
    "\n",
    "#             log_odds = np.log(corrected_score/incorrected_score)\n",
    "#             score_  = np.mean(log_odds)\n",
    "\n",
    "            df_iter = df_iter.append({'iteration': i, 'score': score_, 'times': (start+stop)/2, 'epoch' : epoch, 'variable' : variable+'_'+str(hit)}, ignore_index = True)\n",
    "        \n",
    "    times.append('trial_type')\n",
    "    \n",
    "    real_score.append(variable+'_'+str(hit))\n",
    "    a_series = pd.Series(real_score, index = times)\n",
    "    df_real = df_real.append(a_series, ignore_index=True)\n",
    "    \n",
    "    # odds_score.append(variable+'_'+str(hit))\n",
    "    # a_series = pd.Series(odds_score, index = times)\n",
    "    # df_real = df_real.append(a_series, ignore_index=True)\n",
    "    \n",
    "    df_iter = df_iter.fillna(0)\n",
    "    return df_real, df_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd1089-9b41-47b8-998f-60edb3bce6ca",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(df, decode='vector_answer', align='Delay_OFF', start=-0.5, stop=0, cluster_list = [], ratio=0.65, \n",
    "          test_index=[],  train_index=[], fakey=[], delay_only=False):\n",
    "\n",
    "    # df_final, y = interval_extraction_trial(df,variable = decode, align = 'Stimulus_ON', start = -0.25, stop = 0, cluster_list = cluster_list, delay_only=delay_only)\n",
    "    # sc = RobustScaler()\n",
    "    # x =df_final.iloc[:, df_final.columns != 'y']\n",
    "    # sc_fit = sc.fit(x)\n",
    "    \n",
    "    df_final, y = interval_extraction_trial(df,variable = decode, align = align, start = start, stop = stop, cluster_list = cluster_list, delay_only=delay_only)\n",
    "    \n",
    "    # This is mainly for the session shuffles\n",
    "    if len(fakey) > 1:\n",
    "        print('Using shuffled session')\n",
    "        y = fakey[len(fakey)-len(y):]\n",
    "        df_final['y'] = y   \n",
    "        \n",
    "    train_cols = df_final.columns\n",
    "    \n",
    "    #Train the model   \n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final = df_final.drop(columns ='trial')\n",
    "    x = df_final.iloc[:, df_final.columns != 'y']\n",
    "    \n",
    "    if len(test_index) >= 1:\n",
    "        print('Using splits')\n",
    "        train = df_final.loc[train_index,:]\n",
    "        test = df_final.loc[test_index,:]\n",
    "        # print('Fold',str(fold_no),'Class Ratio:',sum(test['y'])/len(test['y']))\n",
    "        x_test = test.iloc[:, test.columns != 'y']\n",
    "        y_test = test['y']\n",
    "        x_train = train.iloc[:, train.columns != 'y']\n",
    "        y_train = train['y']\n",
    "        \n",
    "    else:\n",
    "        x_train = df_final.iloc[:, df_final.columns != 'y']\n",
    "        y_train = df_final['y']\n",
    "        x_test = x_train\n",
    "        y_test = y_train\n",
    "        \n",
    "    #Normalize the X data\n",
    "#     sc_fit = sc.fit(x)\n",
    "\n",
    "#     x_train = sc.transform(x_train)\n",
    "#     x_test = sc.transform(x_test)\n",
    "    \n",
    "    # x_train = sc_fit.transform(x_train)\n",
    "    # x_test = sc_fit.transform(x_test)\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', penalty = 'l2', C=.99).fit(x_train, y_train)\n",
    "    # model = LogisticRegression(solver='liblinear', penalty = 'l1', C=0.95, fit_intercept=True).fit(x_train, y_train)\n",
    "    train_cols = df_final.columns\n",
    "    \n",
    "    p_pred = model.predict_proba(x_test)    \n",
    "    y_pred = model.predict(x_test)    \n",
    "    f1score= f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    y_test = np.where(y_test == -1, 0, y_test) \n",
    "    y_new = y_test.reshape(len(y_test), 1).astype(int)\n",
    "    # y_new = y_test.values.reshape(len(y_test), 1).astype(int)\n",
    "    score_ =  np.take_along_axis(p_pred,y_new,axis=1)   \n",
    "\n",
    "    # print('Trained model on ', len(train_cols), ' neurons.')\n",
    "    print('score:', np.mean(score_), 'f1_score ', f1score)\n",
    "    # p_values = logit_pvalue(model, x_test)\n",
    "    \n",
    "    return model, train_cols,np.mean(score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a684229-c598-4f05-b427-1329385a1626",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interval_extraction_trial(df, cluster_list=[], variable = 'vector_answer', align = 'Delay_OFF', start = 0, stop = 1, delay_only=False):\n",
    "    y = []\n",
    "    d = {}\n",
    "    \n",
    "    if delay_only == False:\n",
    "        # print('Skipping delays')\n",
    "        if align == 'Delay_OFF' and start < 0:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "        if align == 'Delay_OFF' and start < -1:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2) & (df.delay != 1)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 0.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 1.35:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2) & (df.delay != 1)]\n",
    "    \n",
    "    # print('Recovered from: ', str(len(df.trial.unique())), ' trials')\n",
    "    # Create new aligment to the end of the session\n",
    "    df['a_'+align] = df.fixed_times-df[align]\n",
    "\n",
    "    # cluster_list = df_all.cluster_id.unique()\n",
    "    df = df.sort_values('trial')\n",
    "    \n",
    "    y = df.groupby('trial').mean()[variable]\n",
    "\n",
    "    # Filter for the spikes that occur in the interval we are analyzing\n",
    "    df = df.loc[(df['a_'+align]>start)&(df['a_'+align]<stop)]\n",
    "\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final = df.groupby(['trial','cluster_id']).count()\n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final = df_final.pivot_table(index=['trial'], columns='cluster_id', values='fixed_times', fill_value=0).rename_axis(None, axis=1)\n",
    "    df_final = df_final.reindex(cluster_list, axis=1,fill_value=0)\n",
    "\n",
    "    result = pd.merge(df_final, y, how=\"right\", on=[\"trial\"]).fillna(0)\n",
    "    result = result.rename(columns={variable: \"y\"})\n",
    "    result['y'] = np.where(result['y'] == 0, -1, result['y']) \n",
    "    \n",
    "    return result, result['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a6d81c-184b-4fc6-adf9-1f6a70293844",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline = 0.0\n",
    "df_cum_res = pd.DataFrame()\n",
    "df_cum_sti = pd.DataFrame()\n",
    "df_cum_iter = pd.DataFrame()\n",
    "\n",
    "os.chdir('C:/Users/Tiffany/Documents/Ephys/summary_complete')\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    if filename[-3:] != 'pdf':\n",
    "        df = pd.read_csv(filename, sep=',',index_col=0)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    # Variables used for decoder training\n",
    "    decode = 'vector_answer'\n",
    "    align='Delay_OFF'\n",
    "    r=0.25\n",
    "    start= -0.25\n",
    "    stop= 0\n",
    "\n",
    "    type_trial='WM_roll'\n",
    "    hit=1\n",
    "    ratio=0.6\n",
    "    \n",
    "    # #Variables for testing\n",
    "    # colors=['black','crimson']\n",
    "    # variables = ['all','all']\n",
    "    # hits = [1,0]\n",
    "    # ratios = [\"all\",\"all\"]\n",
    "    # variables_combined=[variables[0]+'_'+str(hits[0], variables[1]+'_'+str(hits[1]))]\n",
    "\n",
    "    # # # #Variables for testing\n",
    "    # colors=['darkgreen','indigo']\n",
    "    # variables = ['WM_roll','RL_roll']\n",
    "    # hits = [1, 1]\n",
    "    # ratios = [0.6, 0.4]\n",
    "    # variables_combined=[variables[0]+'_'+str(hits[0]),variables[1]+'_'+str(hits[1])]\n",
    "\n",
    "    #Variables for testing\n",
    "    colors=['darkgreen','crimson','indigo', 'purple']\n",
    "    variables = ['WM_roll','WM_roll','RL_roll','RL_roll']\n",
    "    hits = [1,0,1,0]\n",
    "    ratios = [0.6,0.6,0.4,0.4]\n",
    "    variables_combined=[variables[0]+'_'+str(hits[0]),variables[1]+'_'+str(hits[1]),\n",
    "                        variables[2]+'_'+str(hits[2]),variables[3]+'_'+str(hits[3])]\n",
    " \n",
    "    # colors=['darkgreen','crimson']\n",
    "    # variables = ['WM_roll','WM_roll']\n",
    "    # hits = [1,0]\n",
    "    # ratios = [0.6,0.6]\n",
    "    # variables_combined=[variables[0]+'_'+str(hits[0]),variables[1]+'_'+str(hits[1])]\n",
    "\n",
    "####################################### ----------------- Add 2 more seconds of the previous trials before the current stimulus\n",
    "    # df = df.rename(columns={'past_choices_x' : 'past_choices', 'streak_x' : 'streak', 'past_rewards_x' : 'past_rewards'})\n",
    "    # df = df.drop(columns=['past_choices_y','streak_y', 'past_rewards_y'])\n",
    "\n",
    "    # Create a DataFrame only with info for the session\n",
    "    trials = df.groupby(['trial']).mean()\n",
    "    try:\n",
    "        trials = trials[['START','END','Delay_ON','Delay_OFF', 'Stimulus_ON', 'Response_ON', 'Lick_ON', 'Motor_OUT','new_trial',\n",
    "               'vector_answer', 'reward_side', 'hit', 'delay','total_trials', 'T', 'previous_vector_answer', 'previous_reward_side','repeat_choice',\n",
    "                'WM_roll', 'RL_roll', 'WM', 'RL', 'streak']]\n",
    "    except:\n",
    "        trials = trials[['START','END','Delay_ON','Delay_OFF', 'Stimulus_ON', 'Response_ON', 'Lick_ON', 'Motor_OUT','new_trial',\n",
    "               'vector_answer', 'reward_side', 'hit', 'delay','total_trials', 'T', 'previous_vector_answer', 'previous_reward_side','repeat_choice',\n",
    "                'WM_roll', 'RL_roll', 'WM', 'RL']]\n",
    "    trials = trials.reset_index()\n",
    "\n",
    "    # Make an aligment to END column\n",
    "    df['a_END'] = df['fixed_times'] - df['END']\n",
    "\n",
    "    # Create a new DataFrame with all spikes\n",
    "    try:\n",
    "        # Some sessions include the group column that indicates the type of cluste,r other don't\n",
    "        spikes = df[['trial','fixed_times','a_END','cluster_id', 'group']]\n",
    "    except:\n",
    "        spikes = df[['trial','fixed_times','a_END','cluster_id']]\n",
    "\n",
    "    # Locate spikes that happen 2s prior to end of trial and copy them changing the new_trial index\n",
    "    duplicate_spikes = spikes.loc[spikes.a_END >-2]\n",
    "    duplicate_spikes['trial'] +=1 \n",
    "\n",
    "    # Add the duplicates\n",
    "    spikes = pd.concat([spikes, duplicate_spikes])\n",
    "\n",
    "    # Merge trial data with spikes on trial idnex\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.merge(trials, spikes, on=[\"trial\"])\n",
    "\n",
    "    # Create the columns for start and end and change trial to new trial index ( without taking the misses into account)\n",
    "    # df['trial_start'] = min(df.new_trial)\n",
    "    # df['trial_end'] = max(df.new_trial)\n",
    "    # df = df.drop(columns=['trial'])\n",
    "    # df = df.rename(columns={'new_trial' : 'trial'})\n",
    "\n",
    "    # This in case we don't do this and want to preserve the orginal trial indexes. \n",
    "    df['trial_start'] = min(df.trial)\n",
    "    df['trial_end'] = max(df.trial)\n",
    "\n",
    "    # Crate the aligment that ew will need for the analysis. \n",
    "    df['a_Stimulus_ON'] =  df['fixed_times'] - df['Stimulus_ON']\n",
    "    df['a_Lick_ON'] =  df['fixed_times'] - df['Lick_ON']\n",
    "    df['a_Delay_OFF'] =  df['fixed_times'] - df['Delay_OFF']\n",
    "    df['a_Motor_OUT'] =  df['fixed_times'] - df['Motor_OUT']\n",
    "    df['a_Response_ON'] =  df['fixed_times'] - df['Response_ON']\n",
    "    df['START_adjusted'] =  df['START'] - 2.1\n",
    "    \n",
    "############################################################# -------------------------------------------------------------------------\n",
    "    df['delay'] = np.around(df.delay,2)\n",
    "    df = df.loc[(df.delay!=0.1)&(df.delay!=0.2)]\n",
    "    \n",
    "    if type_trial == 'all' and hit == 'all':\n",
    "        print('All trials')\n",
    "        df_train = df\n",
    "    elif type_trial == 'all':\n",
    "        df_train = df.loc[(df.hit==hit)]\n",
    "    elif hit == 'all':\n",
    "        df_train = df.loc[(df[type_trial]>=ratio)]\n",
    "    else:\n",
    "        df_train = df.loc[(df[type_trial]>=ratio)&(df.hit==hit)]\n",
    "        \n",
    "    cluster_list = df.cluster_id.unique()\n",
    "\n",
    "    df_final, y = interval_extraction_trial(df_train, variable = decode, align = align, start = start, stop = stop, cluster_list=cluster_list)\n",
    "    df_final.reset_index(inplace=True)\n",
    "    with_trial_df = df_final\n",
    "    df_final = df_final.drop(columns ='trial')\n",
    "\n",
    "    fig, ([ax1,ax2])  = plt.subplots(1,2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "    print('Number of trials for training: ' , len(y))\n",
    "    \n",
    "    if len(df_final)<5:\n",
    "        continue\n",
    "        \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in skf.split(df_final, y):\n",
    "        \n",
    "        trained_trials = with_trial_df.iloc[train_index].trial.unique()\n",
    "        \n",
    "        x = y.reset_index()\n",
    "        if 1 not in x.iloc[test_index]['y'].values or 1 not in x.iloc[train_index]['y'].values or -1 not in x.iloc[test_index]['y'].values or -1 not in x.iloc[train_index]['y'].values:\n",
    "        # if  1 not in x.iloc[train_index]['y'].values or -1 not in x.iloc[train_index]['y'].values:\n",
    "            print('Skip this session because only one choice')\n",
    "            fold_no+=1\n",
    "            continue\n",
    "            \n",
    "        print('Amount of trials:', len(test_index))\n",
    "\n",
    "        df_res = pd.DataFrame()\n",
    "        df_sti = pd.DataFrame()\n",
    "        df_iter = pd.DataFrame()\n",
    "\n",
    "        model, train_cols, score = train(df_train, decode=decode, align=align, start=start,stop=stop, ratio=ratio, \n",
    "                                 cluster_list = cluster_list, test_index=test_index,  train_index=train_index)\n",
    "        \n",
    "        for color, variable,hit, ratio, left,right in zip(colors,variables,hits, ratios,[ax1, ax1, ax1, ax1],[ax2, ax2, ax2, ax2]):\n",
    "            # Create a dataframe for testing data\n",
    "            print(type_trial, hit)\n",
    "            if type_trial == 'all' and hit == 'all':\n",
    "                df_test = df_train\n",
    "            elif variable == 'all':\n",
    "                df_test = df.loc[(df.hit==hit)]\n",
    "            elif hit == 'all':\n",
    "                df_test = df.loc[(df[variable]>=ratio)]\n",
    "            else:\n",
    "                df_test = df.loc[(df[variable]>=ratio)&(df.hit==hit)]\n",
    "            \n",
    "            print(variable + str(ratio) + '_' + str(hit))\n",
    "                \n",
    "            # -----------  Remove the trials that overlap with the training set.                          \n",
    "            # print(df_test.trial.unique(), trained_trials)\n",
    "            df_test = df_test[~df_test['trial'].isin(trained_trials)] \n",
    "            # print(df_test.trial.unique())\n",
    "            test_index=[]\n",
    "            if len(df_test.trial.unique()) <2:\n",
    "                continue\n",
    "\n",
    "            df_real,df_temp = test(df_test, epoch='Stimulus_ON',initrange=-2,endrange=1.4, r=r, model = model, cluster_list=cluster_list,\n",
    "                                    variable=variable, hit=hit, nsurrogates = 100, ratio=ratio, test_index = test_index,\n",
    "                                   train_cols =  train_cols)\n",
    "\n",
    "            df_sti = pd.concat([df_real,df_sti])\n",
    "            df_iter = pd.concat([df_iter,df_temp])\n",
    "\n",
    "            df_real,df_temp = test(df_test, decode= decode,  epoch='Delay_OFF',initrange=-1,endrange=4.5,r=r, model = model, cluster_list=cluster_list, \n",
    "                                    variable=variable, hit=hit,  nsurrogates = 100, ratio=ratio, test_index = test_index,\n",
    "                                   train_cols =  train_cols)\n",
    "\n",
    "            df_res = pd.concat([df_real,df_res])\n",
    "            df_iter = pd.concat([df_iter,df_temp])\n",
    "\n",
    "            variable = str(variable)+'_'+str(hit)\n",
    "            \n",
    "            y_lower = 0\n",
    "            y_upper=0\n",
    "\n",
    "            # Aligmnent for Stimulus cue\n",
    "            real = np.array(df_sti.loc[df_sti['trial_type'] ==variable].mean(axis=0))\n",
    "            times = np.array(df_sti.columns)[:-1].astype(float)\n",
    "\n",
    "            if color=='indigo':\n",
    "                left.set_xlabel('Time (s) to Cue')\n",
    "            sns.despine()\n",
    "\n",
    "            df_new = pd.DataFrame()\n",
    "            for iteration in np.arange(1,100):\n",
    "                df_new[iteration]= df_iter.loc[(df_iter.variable==variable)&(df_iter.iteration==iteration)&(df_iter.epoch=='Stimulus_ON')].groupby('times').mean()['score']\n",
    "\n",
    "            y_mean= df_new.mean(axis=1).values\n",
    "            upper =  df_new.quantile(q=0.975, interpolation='linear',axis=1) - y_mean\n",
    "            lower =  df_new.quantile(q=0.025, interpolation='linear',axis=1) - y_mean\n",
    "            # upper =  df_new.quantile(q=0.975, interpolation='linear',axis=1)\n",
    "            # lower =  df_new.quantile(q=0.025, interpolation='linear',axis=1)\n",
    "            x=times\n",
    "\n",
    "            try:\n",
    "                a_series = pd.DataFrame(pd.Series(real-y_mean, index = times)).T\n",
    "                # a_series = pd.DataFrame(pd.Series(real, index = times)).T\n",
    "                a_series['subject'] = filename[:3]\n",
    "                a_series['trial_type'] = variable\n",
    "                a_series['session'] = filename\n",
    "                a_series['fold'] = fold_no\n",
    "                a_series['score'] = score\n",
    "\n",
    "                df_cum_sti = df_cum_sti.append(a_series, ignore_index=True)\n",
    "            except:\n",
    "                print('Did not add to summary: ', variable)\n",
    "                continue\n",
    "\n",
    "            # plt.plot(x, y_mean, label='Non-prefered Stimulus', color=color)\n",
    "            left.plot(times,real-y_mean, color=color)\n",
    "            # left.plot(times,real, color=color)\n",
    "            left.plot(x, lower, color=color, linestyle = '',alpha=0.6)\n",
    "            left.plot(x, upper, color=color, linestyle = '',alpha=0.6)\n",
    "            left.fill_between(x, lower, upper, alpha=0.2, color=color)\n",
    "            if max(real-y_mean)>y_upper:\n",
    "                y_upper = max(upper)\n",
    "            if  min(real-y_mean)<y_lower:\n",
    "                y_lower = min(lower)\n",
    "            left.set_ylim(-0.5,1)\n",
    "            left.axhline(y=baseline,linestyle=':',color='black')\n",
    "            left.fill_betweenx(np.arange(-1.15,4.15,0.1), 0,0.45, color='grey', alpha=.4)\n",
    "            sns.despine()\n",
    "\n",
    "            # -------------------- For Aligment to Go cue\n",
    "\n",
    "            real = np.array(df_res.loc[df_res['trial_type'] == variable].mean(axis=0))\n",
    "            times = np.array(df_res.columns)[:-1].astype(float)\n",
    "\n",
    "            df_new = pd.DataFrame()\n",
    "            for iteration in np.arange(1,100):\n",
    "                df_new[iteration]= df_iter.loc[(df_iter.variable==variable)&(df_iter.iteration==iteration)&(df_iter.epoch=='Delay_OFF')].groupby('times').mean()['score']\n",
    "\n",
    "            y_mean= df_new.mean(axis=1).values\n",
    "            upper =  df_new.quantile(q=0.975, interpolation='linear',axis=1) - y_mean\n",
    "            lower =  df_new.quantile(q=0.025, interpolation='linear',axis=1) - y_mean\n",
    "            # upper =  df_new.quantile(q=0.975, interpolation='linear',axis=1)\n",
    "            # lower =  df_new.quantile(q=0.025, interpolation='linear',axis=1)\n",
    "            x=times\n",
    "\n",
    "            # ax2.plot(x, y_mean, color=color)\n",
    "\n",
    "            right.plot(times,real-y_mean, color=color)\n",
    "            # right.plot(times,real, color=color)\n",
    "            right.plot(x, lower , color=color, linestyle = '',alpha=0.6)\n",
    "            right.plot(x, upper , color=color, linestyle = '',alpha=0.6)\n",
    "            right.fill_between(x, lower, upper, alpha=0.2, color=color)\n",
    "            right.set_ylim(-0.2,0.5)\n",
    "            right.axhline(y=baseline,linestyle=':',color='black')\n",
    "            right.fill_betweenx(np.arange(-1.125,4.1,0.1), 0,0.2, color='beige', alpha=.8)\n",
    "            if color=='indigo':\n",
    "                right.set_xlabel('Time (s) to Go')\n",
    "\n",
    "            sns.despine()\n",
    "\n",
    "            try:\n",
    "                a_series = pd.DataFrame(pd.Series(real-y_mean, index = times)).T\n",
    "                # a_series = pd.DataFrame(pd.Series(real, index = times)).T\n",
    "                a_series['subject'] = filename[:3]\n",
    "                a_series['trial_type'] = variable\n",
    "                a_series['session'] = filename\n",
    "                a_series['fold'] = fold_no\n",
    "                a_series['score'] = score\n",
    "\n",
    "                df_cum_res = df_cum_res.append(a_series, ignore_index=True)\n",
    "            except:\n",
    "                print('Did not add to summary: ', variable)\n",
    "                continue\n",
    "\n",
    "            fold_no+=1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25fb3f6-bdb8-47a6-bfa4-d3a5453c51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_combined=['all_1', 'all_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9f266-8a27-435b-b778-1f4939a5485d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ([ax1,ax2])  = plt.subplots(1,2, figsize=(14, 4), sharey=True)\n",
    "for color, variable,left,right in zip(colors,variables_combined,[ax1, ax1, ax1, ax1],[ax2, ax2, ax2, ax2]):\n",
    "    print(variable)\n",
    "    # Aligmnent for Stimulus cue\n",
    "    # real = np.array(df_cum_sti.loc[:, df_cum_sti.columns != 'session'].mean())\n",
    "    # real = df_cum_sti.groupby('session').mean()\n",
    "    real = np.array(np.mean(df_cum_sti.loc[(df_cum_sti['trial_type'] == variable)].groupby('session').median().drop(columns=['score','fold']))) \n",
    "    # real = np.array(np.mean(df_cum_sti.groupby('session').median()))\n",
    "    times = df_cum_sti.loc[(df_cum_sti['trial_type'] == variable)]\n",
    "    times = np.array(times.drop(columns=['session','fold','score','subject','trial_type'],axis = 1).columns.astype(float))\n",
    "    # times = np.array(df_cum_sti.columns[:-3]).astype(float)\n",
    "\n",
    "    left.set_xlabel('Time (s) to Cue')\n",
    "    sns.despine()\n",
    "\n",
    "    df_lower = pd.DataFrame()\n",
    "    df_upper = pd.DataFrame()\n",
    "\n",
    "    for timepoint in times:\n",
    "        mean_surr = []\n",
    "\n",
    "        # recover the values for that specific timepoint\n",
    "        try:\n",
    "            array = df_cum_sti.loc[(df_cum_sti.trial_type ==variable)].drop(columns='subject').groupby('session').mean()[str(timepoint)].to_numpy()\n",
    "        except:\n",
    "            array = df_cum_sti.loc[(df_cum_sti.trial_type ==variable)].drop(columns='subject').groupby('session').mean()[timepoint].to_numpy()\n",
    "        array = array[~np.isnan(array)]\n",
    "        # iterate several times with resampling: chose X time among the same list of values\n",
    "        for iteration in range(1000):\n",
    "            x = np.random.choice(array, size=len(array), replace=True)\n",
    "            # recover the mean of that new distribution\n",
    "            mean_surr.append(np.mean(x))\n",
    "\n",
    "        df_lower.at[0,timepoint] = np.percentile(mean_surr, 2.5)\n",
    "        df_upper.at[0,timepoint] = np.percentile(mean_surr, 97.5)\n",
    "\n",
    "    lower =  df_lower.iloc[0].values\n",
    "    upper =  df_upper.iloc[0].values\n",
    "    # lower =  real - 2*df_for_boots.std()\n",
    "    # upper =  real + 2*df_for_boots.std()\n",
    "    # lower =  df_cum_sti.quantile(0.025)\n",
    "    # upper =  df_cum_sti.quantile(0.975)\n",
    "    x=times\n",
    "\n",
    "    # plt.plot(x, y_mean, label='Non-prefered Stimulus', color=color)\n",
    "    left.plot(times,real, color=color)\n",
    "    left.plot(x, lower, color=color, linestyle = '',alpha=0.6)\n",
    "    left.plot(x, upper, color=color, linestyle = '',alpha=0.6)\n",
    "    left.fill_between(x, lower, upper, alpha=0.2, color=color)\n",
    "    left.set_ylim(0.4,0.8)\n",
    "    left.axhline(y=0.0,linestyle=':',color='black')\n",
    "    left.fill_betweenx(np.arange(-1,3.15,0.1), 0,0.45, color='grey', alpha=.4)\n",
    "    sns.despine()\n",
    "\n",
    "    # -------------------- For Aligment to Go cue\n",
    "    # real = np.array(df_cum_res.loc[:, df_cum_res.columns != 'session'].mean())\n",
    "    # real =  np.array(np.mean(df_cum_res.groupby('session').median()))\n",
    "    # times = np.array(df_cum_res.columns[:-3]).astype(float)\n",
    "    \n",
    "    real = np.array(np.mean(df_cum_res.loc[(df_cum_res['trial_type'] == variable)].groupby('session').median().drop(columns=['score','fold'])))\n",
    "    times = df_cum_res.loc[(df_cum_res['trial_type'] == variable)]\n",
    "    times = np.array(times.drop(columns=['session','fold','score','subject','trial_type'],axis = 1).columns.astype(float))\n",
    "    \n",
    "    df_lower = pd.DataFrame()\n",
    "    df_upper = pd.DataFrame()\n",
    "\n",
    "    for timepoint in times:\n",
    "        mean_surr = []\n",
    "\n",
    "        # recover the values for that specific timepoint\n",
    "        try:\n",
    "            array = df_cum_res.loc[(df_cum_res.trial_type ==variable)].drop(columns='subject').groupby('session').mean()[str(timepoint)].to_numpy()\n",
    "        except:\n",
    "            array = df_cum_res.loc[(df_cum_res.trial_type ==variable)].drop(columns='subject').groupby('session').mean()[timepoint].to_numpy()\n",
    "        array = array[~np.isnan(array)]\n",
    "        # iterate several times with resampling: chose X time among the same list of values\n",
    "        for iteration in range(1000):\n",
    "            x = np.random.choice(array, size=len(array), replace=True)\n",
    "            # recover the mean of that new distribution\n",
    "            mean_surr.append(np.mean(x))\n",
    "\n",
    "        df_lower.at[0,timepoint] = np.percentile(mean_surr, 2.5)\n",
    "        df_upper.at[0,timepoint] = np.percentile(mean_surr, 97.5)\n",
    "\n",
    "    lower =  df_lower.iloc[0].values\n",
    "    upper =  df_upper.iloc[0].values\n",
    "    # lower =  real - 2*df_for_boots.std()\n",
    "    # upper =  real + 2*df_for_boots.std()\n",
    "    # lower =  df_cum_res.quantile(0.025)\n",
    "    # upper =  df_cum_res.quantile(0.975)\n",
    "    \n",
    "    # lower = -np.mean(df_cum_res.loc[df_cum_sti['trial_type'] ==variable].groupby(['session','fold']).sem(),axis=0)*2\n",
    "    # upper = np.mean(df_cum_res.loc[df_cum_sti['trial_type'] ==variable].groupby(['session','fold']).sem(),axis=0)*2\n",
    "    x=times\n",
    "\n",
    "    # ax2.plot(x, y_mean, color=color)\n",
    "    right.plot(times,real, color=color)\n",
    "    right.plot(x, lower, color=color, linestyle = '',alpha=0.6)\n",
    "    right.plot(x, upper, color=color, linestyle = '',alpha=0.6)\n",
    "    right.fill_between(x, lower, upper, alpha=0.2, color=color)\n",
    "    right.set_ylim(-0.1,0.2)\n",
    "    right.axhline(y=0.0,linestyle=':',color='black')\n",
    "    right.fill_betweenx(np.arange(-1.1,3.1,0.1), 0,0.2, color='beige', alpha=.8)\n",
    "    right.set_xlabel('Time (s) to Go')\n",
    "    right.set_xlim(-1,2)\n",
    "\n",
    "    sns.despine()\n",
    "#     plt.ylim(0.4,0.8)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(save_path+'/decoder_'+decode+'_'+align+'_'+trials+'start'+str(start)+'_stop'+str(stop)+'_summary.svg', dpi=300, bbox_inches='tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdb117a-d765-41d4-a72c-aefb5a7ecea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/Tiffany/Google Drive/WORKING_MEMORY/PAPER/Figures/'\n",
    "os.chdir(save_path)\n",
    "\n",
    "file_name = 'all_all1 and 0 delay code'\n",
    "# df_cum_sti.to_csv(file_name+'_sti.csv')\n",
    "# df_cum_res.to_csv(file_name+'_res.csv')\n",
    "df_cum_sti = pd.read_csv(file_name+'_sti.csv', index_col=0)\n",
    "df_cum_res = pd.read_csv(file_name+'_res.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab2f98-89db-4052-b0bf-dc09bdba2c0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Figure for all trials code but using single delays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e26717f-ca99-4c4a-826b-7ad65c339645",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interval_extraction_trial(df, cluster_list=[], variable = 'vector_answer', align = 'Delay_OFF', start = 0, stop = 1, delay_only=False):\n",
    "    y = []\n",
    "    d = {}\n",
    "    \n",
    "    if delay_only == False:\n",
    "        # print('Skipping delays')\n",
    "        if align == 'Delay_OFF' and start < 0:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "        if align == 'Delay_OFF' and start < -1:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2) & (df.delay != 1)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 0.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2)]\n",
    "\n",
    "        if align == 'Stimulus_ON' and stop > 1.5:\n",
    "            df = df.loc[(df.delay != 0.1) & (df.delay != 0.2) & (df.delay != 1)]\n",
    "    \n",
    "    # print('Recovered from: ', str(len(df.trial.unique())), ' trials')\n",
    "    # Create new aligment to the end of the session\n",
    "    df['a_'+align] = df.fixed_times-df[align]\n",
    "\n",
    "    # cluster_list = df_all.cluster_id.unique()\n",
    "    df = df.sort_values('trial')\n",
    "    \n",
    "    y = df.groupby('trial').mean()[variable]\n",
    "\n",
    "    # Filter for the spikes that occur in the interval we are analyzing\n",
    "    df = df.loc[(df['a_'+align]>start)&(df['a_'+align]<stop)]\n",
    "\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final = df.groupby(['trial','cluster_id']).count()\n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final = df_final.pivot_table(index=['trial'], columns='cluster_id', values='fixed_times', fill_value=0).rename_axis(None, axis=1)\n",
    "    df_final = df_final.reindex(cluster_list, axis=1,fill_value=0)\n",
    "\n",
    "    result = pd.merge(df_final, y, how=\"right\", on=[\"trial\"]).fillna(0)\n",
    "    result = result.rename(columns={variable: \"y\"})\n",
    "    result['y'] = np.where(result['y'] == 0, -1, result['y']) \n",
    "    \n",
    "    return result, result['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9c0da-7973-409a-bd9a-09660977e729",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(df, decode='vector_answer', align='Delay_OFF', start=-0.5, stop=0, cluster_list = [], ratio=0.65, test_index=[],  train_index=[], fakey=[], delay_only=False):\n",
    "\n",
    "    df_final, y = interval_extraction_trial(df,variable = decode, align = 'Stimulus_ON', start = -0.25, stop = 0, cluster_list = cluster_list, delay_only=delay_only)\n",
    "    sc = RobustScaler()\n",
    "    x =df_final.iloc[:, df_final.columns != 'y']\n",
    "    sc_fit = sc.fit(x)\n",
    "    \n",
    "    df_final, y = interval_extraction_trial(df,variable = decode, align = align, start = start, stop = stop, cluster_list = cluster_list, delay_only=delay_only)\n",
    "    \n",
    "    # This is mainly for the session shuffles\n",
    "    if len(fakey) > 1:\n",
    "        print('Using shuffled session')\n",
    "        y = fakey[len(fakey)-len(y):]\n",
    "        df_final['y'] = y   \n",
    "        \n",
    "    train_cols = df_final.columns\n",
    "    \n",
    "    #Train the model   \n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final = df_final.drop(columns ='trial')\n",
    "    \n",
    "    if len(test_index) >= 1:\n",
    "        print('Using splits')\n",
    "        train = df_final.loc[train_index,:]\n",
    "        test = df_final.loc[test_index,:]\n",
    "        # print('Fold',str(fold_no),'Class Ratio:',sum(test['y'])/len(test['y']))\n",
    "        x_test = test.iloc[:, test.columns != 'y']\n",
    "        y_test = test['y']\n",
    "        x_train = train.iloc[:, train.columns != 'y']\n",
    "        y_train = train['y']\n",
    "        \n",
    "    else:\n",
    "        x_train = df_final.iloc[:, df_final.columns != 'y']\n",
    "        y_train = df_final['y']\n",
    "        x_test = x_train\n",
    "        y_test = y_train\n",
    "        \n",
    "    #Normalize the X data\n",
    "    # sc = RobustScaler()\n",
    "    # sc_fit = sc.fit(df_final.iloc[:, df_final.columns != 'y'])\n",
    "    \n",
    "    # x_train = sc.fit_transform(x_train)\n",
    "    # x_test = sc.fit_transform(x_test)\n",
    "    \n",
    "    # x_train = sc_fit.transform(x_train)\n",
    "    # x_test = sc_fit.transform(x_test)\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', penalty = 'l1', C=0.99).fit(x_train, y_train)\n",
    "    # model = LogisticRegression(solver='liblinear', penalty = 'l1', C=0.95, fit_intercept=True).fit(x_train, y_train)\n",
    "    train_cols = df_final.columns\n",
    "    \n",
    "    p_pred = model.predict_proba(x_test)    \n",
    "    y_pred = model.predict(x_test)    \n",
    "    f1score= f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    y_test = np.where(y_test == -1, 0, y_test) \n",
    "    y_new = y_test.reshape(len(y_test), 1).astype(int)\n",
    "    # y_new = y_test.values.reshape(len(y_test), 1).astype(int)\n",
    "    score_ =  np.take_along_axis(p_pred,y_new,axis=1)   \n",
    "\n",
    "    # print('Trained model on ', len(train_cols), ' neurons.')\n",
    "    print('score:', np.mean(score_), 'f1_score ', f1score)\n",
    "    \n",
    "    return model, train_cols, np.mean(score_), sc_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b3ea7-29d3-4b76-9b86-843fc1362f2a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(df,sc_fit, epoch='Stimulus_ON',initrange=-0.4,endrange=1.5,r=0.2, model = None, train_cols=None, variable='ra_accuracy',\n",
    "                      hit=1, nsurrogates = 100, decode='vector_answer', ratio=0, cluster_list = [], test_index=[], fakey=[], delay_only=False):\n",
    "    '''\n",
    "    Function that tests a previously trained function (func. train_decoder) on population activity of specific segments\n",
    "    \n",
    "    Attributes\n",
    "        - df: DataFrame. it contains a whole ephys session without curation. \n",
    "        - WM and RL are the variables to consider a trial in the RL or in the WM-module. Both need to be floats. \n",
    "        - epoch: str. Moment at which the data will be aligned to. \n",
    "        - initrange: float. \n",
    "        - endrange: float.\n",
    "        - r: float \n",
    "        - model. function. \n",
    "        - train_cols\n",
    "        - name. String\n",
    "        - variables. List. \n",
    "        - hits. List. \n",
    "        - colors. List\n",
    "        - nsurrogates. Int. \n",
    "        - indexes. List \n",
    "        - decode. String\n",
    "    \n",
    "    Return\n",
    "        - df_real\n",
    "        - df_iter\n",
    "        It will also make a plot. \n",
    "    '''\n",
    "    \n",
    "    df_real = pd.DataFrame()\n",
    "    df_iter = pd.DataFrame()\n",
    "        \n",
    "    times = [] # Timestamps\n",
    "    real_score = [] # real scoring of the decoded\n",
    "    mean_sur=[] # mean of the surrogate data\n",
    "\n",
    "    for start, stop in zip(np.arange(initrange,endrange-r,r),np.arange(initrange+r,endrange,r)):\n",
    "        times.append((start+stop)/2)\n",
    "        df_final, y = interval_extraction_trial(df,variable = decode, align = epoch, start = start, stop = stop, cluster_list=cluster_list, delay_only=delay_only)\n",
    "\n",
    "        # Sometimes the testing and the trainind dataset have different neurons since they are looking at different trials and perhaps there were no spikes\n",
    "        # coming from all neurons. We compare which columns are missing and add them containing 0 for the model to work. \n",
    "        test_cols = df_final.columns\n",
    "        common_cols = train_cols.intersection(test_cols)\n",
    "        train_not_test = train_cols.difference(test_cols)\n",
    "        for col in train_not_test:\n",
    "            df_final[col] = 0\n",
    "\n",
    "        #The other way round. When training in segmented data, sometimes the training set is smaller than the testing (for instance, when training in Hb trials and testing in WM)\n",
    "        test_not_train = test_cols.difference(train_cols)\n",
    "        for col in test_not_train:\n",
    "            df_final.drop(columns=[col],inplace=True)\n",
    "\n",
    "        #Train the model\"\n",
    "        if len(test_index) >= 1:\n",
    "            print('Train splitting trials')\n",
    "            # Split data in training and testing\n",
    "            # x_train, x_test, y_train, y_test =\\\n",
    "            #     train_test_split(df_final, y, test_size=test_sample,random_state=random_state)\n",
    "            \n",
    "            df_final.reset_index(inplace=True)\n",
    "            df_final = df_final.drop(columns ='trial')\n",
    "            test = df_final.loc[test_index,:]\n",
    "            # print('Fold',str(fold_no),'Class Ratio:',sum(test['y'])/len(test['y']))\n",
    "            x_test = test.iloc[:, test.columns != 'y']\n",
    "            y_test = test['y']             \n",
    "\n",
    "        else:\n",
    "            x_train = df_final.iloc[:, df_final.columns != 'y']\n",
    "            y_train = df_final['y']\n",
    "            x_test = x_train\n",
    "            y_test = y_train\n",
    "        \n",
    "        #Normalize the X data\n",
    "        # sc = RobustScaler()\n",
    "        # x_test = sc.fit_transform(x_test)\n",
    "        # x_test = sc_fit.transform(x_test)\n",
    "        \n",
    "        p_pred = model.predict_proba(x_test)\n",
    "        y_pred = model.predict(x_test)\n",
    "        score_ = model.score(x_test, y_test)\n",
    "        real_score.append(score_)\n",
    "\n",
    "        # y_test = np.where(y_test == -1, 0, y_test) \n",
    "        # y_new = y_test.reshape(len(y_test), 1).astype(int)\n",
    "        # corrected_score =  np.take_along_axis(p_pred,y_new,axis=1)   \n",
    "        # real_score.append(np.mean(corrected_score))\n",
    "\n",
    "        # print('score:', score_, 'corrected score: ', np.mean(corrected_score), end='\\n\\n')\n",
    "\n",
    "        i=0\n",
    "        while i <= nsurrogates:\n",
    "            i+=1\n",
    "            y_perr = shuffle(y_test)\n",
    "            score_ = model.score(x_test, y_perr)\n",
    "\n",
    "            # y_new = y_perr.reshape(len(y_perr), 1).astype(int)\n",
    "            # result =  np.take_along_axis(p_pred,y_new,axis=1)     \n",
    "            # score_  = np.mean(result)\n",
    "\n",
    "            df_iter = df_iter.append({'iteration': i, 'score': score_, 'times': (start+stop)/2, 'epoch' : epoch, 'variable' : variable+'_'+str(hit)}, ignore_index = True)\n",
    "        \n",
    "    times.append('trial_type')\n",
    "    real_score.append(variable+'_'+str(hit))\n",
    "    a_series = pd.Series(real_score, index = times)\n",
    "    df_real = df_real.append(a_series, ignore_index=True)\n",
    "    \n",
    "    return df_real, df_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed3d73-215d-45a9-8dc0-09a91b500a09",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Dataframe used for cumulative analysis\n",
    "df_cum_sti = pd.DataFrame()\n",
    "df_cum_shuffle = pd.DataFrame()\n",
    "\n",
    "os.chdir('C:/Users/Tiffany/Documents/Ephys/summary_complete')\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "# for filename in list_of_sessions:\n",
    "    # \n",
    "    if filename[-3:] != 'pdf':\n",
    "        df = pd.read_csv(filename, sep=',',index_col=0)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    print(filename, '/ Total session trials: ', len(df.trial.unique()), '/ Number of neurons: ', len(df.cluster_id.unique()))\n",
    "    \n",
    "    # df['WM_roll'] = compute_window_centered(df, 3,'WM')\n",
    "\n",
    "####################################### ----------------- Add 2 more seconds of the previous trials before the current stimulus\n",
    "    # df = df.rename(columns={'past_choices_x' : 'past_choices', 'streak_x' : 'streak', 'past_rewards_x' : 'past_rewards'})\n",
    "    # df = df.drop(columns=['past_choices_y','streak_y', 'past_rewards_y'])\n",
    "\n",
    "    # Create a DataFrame only with info for the session\n",
    "    trials = df.groupby(['trial']).mean()\n",
    "    try:\n",
    "        trials = trials[['START','END','Delay_ON','Delay_OFF', 'Stimulus_ON', 'Response_ON', 'Lick_ON', 'Motor_OUT','new_trial',\n",
    "               'vector_answer', 'reward_side', 'hit', 'delay','total_trials', 'T', 'previous_vector_answer', 'previous_reward_side','repeat_choice',\n",
    "                'WM_roll', 'RL_roll', 'WM', 'RL', 'streak']]\n",
    "    except:\n",
    "        trials = trials[['START','END','Delay_ON','Delay_OFF', 'Stimulus_ON', 'Response_ON', 'Lick_ON', 'Motor_OUT','new_trial',\n",
    "               'vector_answer', 'reward_side', 'hit', 'delay','total_trials', 'T', 'previous_vector_answer', 'previous_reward_side','repeat_choice',\n",
    "                'WM_roll', 'RL_roll', 'WM', 'RL']]\n",
    "    trials = trials.reset_index()\n",
    "\n",
    "    # Make an aligment to END column\n",
    "    df['a_END'] = df['fixed_times'] - df['END']\n",
    "\n",
    "    # Create a new DataFrame with all spikes\n",
    "    try:\n",
    "        # Some sessions include the group column that indicates the type of cluste,r other don't\n",
    "        spikes = df[['trial','fixed_times','a_END','cluster_id', 'group']]\n",
    "    except:\n",
    "        spikes = df[['trial','fixed_times','a_END','cluster_id']]\n",
    "\n",
    "    # Locate spikes that happen 2s prior to end of trial and copy them changing the new_trial index\n",
    "    duplicate_spikes = spikes.loc[spikes.a_END >-4]\n",
    "    duplicate_spikes['trial'] +=1 \n",
    "\n",
    "    # Add the duplicates\n",
    "    spikes = pd.concat([spikes, duplicate_spikes])\n",
    "\n",
    "    # Merge trial data with spikes on trial idnex\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.merge(trials, spikes, on=[\"trial\"])\n",
    "\n",
    "    # Create the columns for start and end and change trial to new trial index ( without taking the misses into account)\n",
    "    # df['trial_start'] = min(df.new_trial)\n",
    "    # df['trial_end'] = max(df.new_trial)\n",
    "    # df = df.drop(columns=['trial'])\n",
    "    # df = df.rename(columns={'new_trial' : 'trial'})\n",
    "\n",
    "    # This in case we don't do this and want to preserve the orginal trial indexes. \n",
    "    df['trial_start'] = min(df.trial)\n",
    "    df['trial_end'] = max(df.trial)\n",
    "\n",
    "    # Crate the aligment that ew will need for the analysis. \n",
    "    df['a_Stimulus_ON'] =  df['fixed_times'] - df['Stimulus_ON']\n",
    "    df['a_Lick_ON'] =  df['fixed_times'] - df['Lick_ON']\n",
    "    df['a_Delay_OFF'] =  df['fixed_times'] - df['Delay_OFF']\n",
    "    df['a_Motor_OUT'] =  df['fixed_times'] - df['Motor_OUT']\n",
    "    df['a_Response_ON'] =  df['fixed_times'] - df['Response_ON']\n",
    "    df['START_adjusted'] =  df['START'] - 4.1\n",
    "    \n",
    "############################################################# -------------------------------------------------------------------------\n",
    "\n",
    "    substract = False\n",
    "    df['delay'] = np.around(df.delay,2)\n",
    "    \n",
    "    # Variables used for decoder training\n",
    "    decode = 'vector_answer'\n",
    "    align='Delay_OFF'\n",
    "    ratio = 0.6\n",
    "    start = -0.25\n",
    "    stop = 0\n",
    "    type_trial ='all'\n",
    "    hit = 1\n",
    "    nsplits = 3\n",
    "    \n",
    "    #Variables for testing\n",
    "    # colors=['darkgreen','crimson', 'indigo']\n",
    "    # variables = ['WM_roll','WM_roll','RL_roll']\n",
    "    # hits = [1,0,1]\n",
    "    # ratios = [0.6,0.6,0.4]\n",
    "    # variables_combined=[variables[0]+'_'+str(hits[0]),variables[1]+'_'+str(hits[1]),variables[2]+'_'+str(hits[2])]\n",
    "\n",
    "    colors=['crimson','darkgreen']\n",
    "    variables = ['all','all']\n",
    "    hits = [0,1]\n",
    "    ratios = [\"all\",\"all\"]\n",
    "    variables_combined=[variables[0]+'_'+str(hits[0]),variables[1]+'_'+str(hits[1])]\n",
    "\n",
    "    # colors=['crimson','darkgreen','indigo','purple']\n",
    "    # variables = ['WM_roll','WM_roll','RL_roll','RL_roll']\n",
    "    # hits = [0,1,1,0]\n",
    "    # ratios = [0.6,0.6,0.4,0.4]\n",
    "    # variables_combined=[variables[0]+'_'+str(hits[0]),variables[1]+'_'+str(hits[1]),variables[2]+'_'+str(hits[2]),variables[3]+'_'+str(hits[3])]\n",
    "\n",
    "    cluster_list = df.cluster_id.unique()\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=nsplits)\n",
    "    # skf = KFold(n_splits=nsplits, shuffle=True)\n",
    "\n",
    "    # Create a dataframe for training data\n",
    "    if type_trial == 'all':\n",
    "        df_train = df.loc[(df.hit==hit)]\n",
    "    elif hit == 'all':\n",
    "        df_train = df.loc[(df[type_trial]>=ratio)]\n",
    "    else:\n",
    "        df_train = df.loc[(df[type_trial]>=ratio)&(df.hit==hit)]\n",
    "\n",
    "    df_train = df_train.loc[(df_train.delay!=0.2)&(df_train.delay!=0.1)]\n",
    "    \n",
    "    df_final, y = interval_extraction_trial(df_train, variable = decode, align = align, start = start, stop = stop, cluster_list=cluster_list)\n",
    "    df_final.reset_index(inplace=True)\n",
    "    df_final = df_final.drop(columns ='trial')\n",
    "    \n",
    "    fold_no = 1\n",
    "    if len(y) < nsplits:\n",
    "        print('Skip session because not enough trials')\n",
    "        continue\n",
    "        \n",
    "    for train_index, test_index in skf.split(df_final, y):\n",
    "        \n",
    "        print('Fold_no:', fold_no)\n",
    "        model, train_cols, score, sc_fit = train(df_train, decode=decode, align=align, start=start,stop=stop, cluster_list = cluster_list, \n",
    "                                  test_index=test_index,  train_index=train_index)\n",
    "\n",
    "        # Remove a fifth of the dataset so it can be compared to crossvalidated data. If we want to randomly reduce it, add reduce to trian function\n",
    "        # drop_list = np.array_split(df_train.trial.unique(), 5)[fold_no]\n",
    "        # df_train = df_train[~df_train['trial'].isin(drop_list)]\n",
    "        # index_train_trials = df_train.trial.unique()\n",
    "        # print('Total of left: ', len(df_train.loc[df_train['vector_answer'] == 0].groupby('trial').mean()), '; Total of right: ', len(df_train.loc[df_train['vector_answer'] == 1].groupby('trial').mean()))\n",
    "\n",
    "        for delay in df.delay.unique():\n",
    "            try:\n",
    "                df_delay = df.loc[np.around(df.delay,1)==delay]\n",
    "                delay=np.around(df_delay.delay.iloc[0],1)\n",
    "                print('Delay:', delay)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if delay == 0.1 or delay == 0.2:\n",
    "                endrange=3.5\n",
    "                r=0.25\n",
    "            elif delay == 1:\n",
    "                endrange=4.5\n",
    "                r=0.25\n",
    "            elif delay == 3:\n",
    "                endrange=6.5    \n",
    "                r=0.25\n",
    "            elif delay == 10:\n",
    "                endrange=14.5\n",
    "                r=0.25\n",
    "\n",
    "            if delay == 0.1:\n",
    "                fig, ax1 = plt.subplots(1,1, figsize=(10, 4), sharey=True)\n",
    "            elif delay == 1:\n",
    "                fig, ax1 = plt.subplots(1,1, figsize=(10, 4), sharey=True)\n",
    "            elif int(delay) == 3:\n",
    "                fig, ax1 = plt.subplots(1,1, figsize=(12, 4), sharey=True)\n",
    "            elif delay == 10:\n",
    "                fig, ax1 = plt.subplots(1,1, figsize=(14, 4), sharey=True)\n",
    "\n",
    "            df_res = pd.DataFrame()\n",
    "            df_sti = pd.DataFrame()\n",
    "            df_iter = pd.DataFrame()\n",
    "\n",
    "            for color, variable,hit,ratio,left in zip(colors,variables,hits,ratios,[ax1,ax1,ax1,ax1]):\n",
    "\n",
    "                # Create a dataframe for testing data\n",
    "                if variable == 'all':\n",
    "                    df_test = df_delay.loc[(df_delay.hit==hit)]\n",
    "                elif hit == 'all':\n",
    "                    df_test = df_delay.loc[(df_delay[variable]>=ratio)]\n",
    "                else:\n",
    "                    df_test = df_delay.loc[(df_delay[variable]>=ratio)&(df_delay.hit==hit)]\n",
    "                    \n",
    "                if fold_no == 1:\n",
    "                    print(variable, 'Threshold:', ratio, 'Hit:', hit, 'Nº of trials:', len(df_test.trial.unique()))\n",
    "\n",
    "    # -----------  Remove the trials that overlap with the training set.\n",
    "                list_train_trials = df_train.trial.unique()[train_index]\n",
    "                df_test = df_test[~df_test['trial'].isin(list_train_trials)] \n",
    "                \n",
    "                if len(df_test.trial.unique())<5:\n",
    "                    print('Not enough trials with this condition')\n",
    "                    continue\n",
    "\n",
    "                df_real,df_temp = test(df_test, sc_fit, decode= decode,epoch='Stimulus_ON',initrange=-2,endrange=endrange, r=r, model = model, delay_only=delay, \n",
    "                                                  variable=variable, hit=hit, nsurrogates = 100,train_cols = train_cols, cluster_list = cluster_list)\n",
    "\n",
    "                df_sti = pd.concat([df_real,df_sti])\n",
    "                df_iter = pd.concat([df_iter,df_temp])\n",
    "\n",
    "                variable = str(variable)+'_'+str(hit)\n",
    "\n",
    "                # Aligmnent for Stimulus cue\n",
    "                real = df_sti.loc[(df_sti['trial_type'] ==variable)].mean(axis=0).to_numpy()\n",
    "                times = np.around(np.array(df_sti.columns)[:-1].astype(float),2)\n",
    "\n",
    "                df_new= df_iter.loc[(df_iter.epoch=='Stimulus_ON')].groupby('times')['score']\n",
    "                y_mean= df_new.mean().values\n",
    "                lower =  df_new.quantile(q=0.975, interpolation='linear')-y_mean\n",
    "                upper =  df_new.quantile(q=0.025, interpolation='linear')-y_mean\n",
    "                x=times\n",
    "\n",
    "                left.set_xlabel('Time to Cue')\n",
    "\n",
    "                if substract == True:\n",
    "                    left.plot(times,real-y_mean, color=color)\n",
    "                    left.plot(x, lower+real-y_mean, color=color, linestyle = '',alpha=0.6)\n",
    "                    left.plot(x, upper+real-y_mean, color=color, linestyle = '',alpha=0.6)\n",
    "                    left.fill_between(x, lower+real-y_mean, upper+real-y_mean, alpha=0.2, color=color)\n",
    "                    left.set_ylim(-0.5,0.6)\n",
    "                    left.axhline(y=0.0,linestyle=':',color='black')\n",
    "                    left.fill_betweenx(np.arange(-1,1.15,0.1), 0,0.4, color='grey', alpha=.4)\n",
    "                    left.fill_betweenx(np.arange(-1.1,1.1,0.1), delay+0.3,delay+0.5, color='beige', alpha=.8)\n",
    "                    try:\n",
    "                        a_series = pd.DataFrame(pd.Series(real-y_mean, index = times)).T\n",
    "                        a_series['trial_type'] = variable\n",
    "                        a_series['session'] = filename\n",
    "                        a_series['delay'] = delay\n",
    "                        a_series['score'] = score    \n",
    "                        a_series['fold'] = fold_no \n",
    "\n",
    "                        df_cum_sti = df_cum_sti.append(a_series, ignore_index=True)\n",
    "\n",
    "                        df_cum_iter=pd.DataFrame()\n",
    "                        df_cum_iter['times'] = df_iter.groupby('times').score.mean().reset_index()['times'].values\n",
    "                        df_cum_iter['delay'] = delay\n",
    "                        df_cum_iter['session'] = filename\n",
    "                        df_cum_iter['fold'] = fold_no \n",
    "                        df_cum_iter['trial_type'] = variable \n",
    "\n",
    "                        for iteration in df_iter.iteration.unique():\n",
    "                            df_cum_iter[iteration]= df_iter.loc[(df_iter.iteration==iteration)].groupby('times').mean()['score'].values - df_iter.groupby('times').mean()['score'].values\n",
    "\n",
    "                        df_cum_shuffle = pd.concat([df_cum_iter, df_cum_shuffle])\n",
    "                    except:\n",
    "                        print('Did not add to summary: ', variable)\n",
    "                        continue\n",
    "                        \n",
    "                elif substract == False:\n",
    "                    left.plot(times,real, color=color)\n",
    "                    left.plot(x, lower+real, color=color, linestyle = '',alpha=0.6)\n",
    "                    left.plot(x, upper+real, color=color, linestyle = '',alpha=0.6)\n",
    "                    left.fill_between(x, lower+real, upper+real, alpha=0.2, color=color)\n",
    "                    left.set_ylim(0,1.1)\n",
    "                    left.axhline(y=0.5,linestyle=':',color='black')\n",
    "                    left.fill_betweenx(np.arange(0,1.15,0.1), 0,0.4, color='grey', alpha=.4)\n",
    "                    left.fill_betweenx(np.arange(0,1.1,0.1), delay+0.3,delay+0.5, color='beige', alpha=.8)\n",
    "\n",
    "                    try:\n",
    "                        a_series = pd.DataFrame(pd.Series(real, index = times)).T\n",
    "                        a_series['trial_type'] = variable\n",
    "                        a_series['session'] = filename\n",
    "                        a_series['delay'] = delay\n",
    "                        a_series['score'] = score    \n",
    "                        a_series['fold'] = fold_no \n",
    "\n",
    "                        df_cum_sti = df_cum_sti.append(a_series, ignore_index=True)\n",
    "\n",
    "                        df_cum_iter=pd.DataFrame()\n",
    "                        df_cum_iter['times'] = df_iter.groupby('times').score.mean().reset_index()['times'].values\n",
    "                        df_cum_iter['delay'] = delay\n",
    "                        df_cum_iter['session'] = filename\n",
    "                        df_cum_iter['fold'] = fold_no \n",
    "                        df_cum_iter['trial_type'] = variable \n",
    "\n",
    "                        for iteration in df_iter.iteration.unique():\n",
    "                            df_cum_iter[iteration]= df_iter.loc[(df_iter.iteration==iteration)].groupby('times').mean()['score'].values\n",
    "\n",
    "                        df_cum_shuffle = pd.concat([df_cum_iter, df_cum_shuffle])\n",
    "                    except:\n",
    "                        print('Did not add to summary: ', variable)\n",
    "                        continue\n",
    "\n",
    "                sns.despine()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fold_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e01828-901d-446e-892b-2d31e27f71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "delays = [1,3,10]\n",
    "y_lower = 0\n",
    "y_upper = 0\n",
    "baseline = 0.0\n",
    "# delays = [1,3,10]\n",
    "\n",
    "for delay in delays:\n",
    "    fig, ax1 = plt.subplots(1,1, figsize=(10, 4), sharey=True)\n",
    "#     if delay == 0.1 and hit ==1:\n",
    "#         fig, ax1 = plt.subplots(1,1, figsize=(10, 4), sharey=True)\n",
    "#     elif delay == 1 and hit ==1:\n",
    "#         fig, ax1 = plt.subplots(1,1, figsize=(10, 4), sharey=True)\n",
    "#     elif delay == 3 and hit ==1:\n",
    "#         fig, ax1 = plt.subplots(1,1, figsize=(12, 4), sharey=True)\n",
    "#     elif delay == 10 and hit ==1:\n",
    "                \n",
    "    for color, variable in zip(colors,variables_combined):\n",
    "        print(variable)\n",
    "        individual_sessions = False\n",
    "        if individual_sessions == True:\n",
    "            # Aligmnent for Stimulus cue - sessions separately\n",
    "            real = df_cum_sti.loc[(df_cum_sti['trial_type'] == variable)&(df_cum_sti['delay'] == delay)].groupby('session').median().reset_index().drop(columns=['fold','session','delay','score'])\n",
    "            try:\n",
    "                times = df_cum_sti.loc[(df_cum_sti['trial_type'] == variable)&(df_cum_sti['delay'] == delay)]\n",
    "                times = np.array(times.drop(columns=['fold','score','trial_type', 'delay','session'],axis = 1).columns.astype(float))\n",
    "            except:\n",
    "                times = np.array(df_cum_sti.columns[1:]).astype(float)\n",
    "        \n",
    "            left.set_xlabel('Time (s) to Cue')\n",
    "        \n",
    "            x=times\n",
    "            for i in range(len(real)):\n",
    "                ax1.plot(times,real.iloc[i], color=color,alpha=0.1)\n",
    "                \n",
    "        # Aligmnent for Stimulus cue\n",
    "        real = np.array(np.mean(df_cum_sti.loc[(df_cum_sti['trial_type'] == variable)&(df_cum_sti['delay'] == delay)].groupby('session').median().drop(columns=['fold','delay','score'])))\n",
    "        \n",
    "    #     times = np.array(df_cum_sti.loc[:, df_cum_sti.columns != 'trial_type' and df_cum_sti.columns != 'trial_type'].columns).astype(float)\n",
    "        times = df_cum_sti.loc[(df_cum_sti['trial_type'] == variable)&(df_cum_sti['delay'] == delay)]\n",
    "        times = np.array(times.drop(columns=['score','trial_type', 'delay','fold','session'],axis = 1).columns.astype(float))\n",
    "        sns.despine()\n",
    "\n",
    "        df_lower = pd.DataFrame()\n",
    "        df_upper = pd.DataFrame()\n",
    "\n",
    "        for timepoint in times:\n",
    "            mean_surr = []\n",
    "\n",
    "            # recover the values for that specific timepoint\n",
    "            try:\n",
    "                array = df_cum_sti.loc[(df_cum_sti.trial_type ==variable)&(df_cum_sti['delay'] == delay)].drop(columns='delay').groupby('session').mean()[str(timepoint)].to_numpy()\n",
    "            except:\n",
    "                array = df_cum_sti.loc[(df_cum_sti.trial_type ==variable)&(df_cum_sti['delay'] == delay)].drop(columns='delay').groupby('session').mean()[timepoint].to_numpy()\n",
    "\n",
    "            # iterate several times with resampling: chose X time among the same list of values\n",
    "            for iteration in range(1000):\n",
    "    \n",
    "                x = np.random.choice(array, size=len(array), replace=True)\n",
    "                # recover the mean of that new distribution\n",
    "                mean_surr.append(np.mean(x))\n",
    "\n",
    "            df_lower.at[0,timepoint] = np.percentile(mean_surr, 2.5)\n",
    "            df_upper.at[0,timepoint] = np.percentile(mean_surr, 97.5)\n",
    "\n",
    "        lower =  df_lower.iloc[0].values\n",
    "        upper =  df_upper.iloc[0].values\n",
    "\n",
    "#         df_new = pd.DataFrame()\n",
    "#         for iteration in np.arange(1,100):\n",
    "#             df_new[iteration]= df_cum_shuffle.loc[(df_cum_shuffle.trial_type==variable)].groupby('times').mean()[iteration]\n",
    "\n",
    "#         y_mean= df_new.mean(axis=1).values\n",
    "#         upper =  df_new.quantile(q=0.975, interpolation='linear',axis=1) - y_mean\n",
    "#         lower =  df_new.quantile(q=0.025, interpolation='linear',axis=1) - y_mean\n",
    "    \n",
    "        x=times\n",
    "\n",
    "        ax1.plot(times,real, color=color)\n",
    "        ax1.plot(x, lower, color=color, linestyle = '',alpha=0.6)\n",
    "        ax1.plot(x, upper, color=color, linestyle = '',alpha=0.6)\n",
    "        ax1.fill_between(x, lower, upper, alpha=0.2, color=color)\n",
    "        ax1.set_ylim(baseline-0.2,baseline+0.3)\n",
    "        ax1.axhline(y=baseline,linestyle=':',color='black')\n",
    "        ax1.fill_betweenx(np.arange(baseline-0.1,baseline+0.5,0.1), 0,0.4, color='grey', alpha=.4)\n",
    "        ax1.fill_betweenx(np.arange(baseline-0.1,baseline+0.5,0.1), delay+0.4,delay+0.6, color='beige', alpha=.8)\n",
    "        if color=='crimson':\n",
    "            ax1.set_xlabel('Time (s) to Go')\n",
    "\n",
    "        sns.despine()\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(save_path+'/delay_'+str(delay)+'_'+align+'_'+trials+'start'+str(start)+'_stop'+str(stop)+'_summary.svg', dpi=300, bbox_inches='tight') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c4b0d-38f4-4719-8418-be2b4a1c8d50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
